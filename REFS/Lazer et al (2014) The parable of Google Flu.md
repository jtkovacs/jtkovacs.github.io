## Lazer, D., Kennedy, R., King, G., & Vespignani, A. (2014). The parable of Google Flu: Traps in Big Data analysis. _Science_, 343.

- [Google Flu Trends](https://www.google.org/flutrends/about/) (GFT), an experiment in __nowcasting__, was consistently high in its predictions (vs [CDC projections](https://www.cdc.gov/flu/weekly/)). Why?
  - __Big Data hubris__: Rejecting the principles of statistics, or failing to combine statistical methods with Big Data analysis as a sanity check
    - In this case, a simple projection based on lagged CDC data outperformed GFT considerably
  - __Algorithm dynamics__: By changing its search algorithms, Google changes the data generation process
- As with most company-sponsored "research", the exercise is not replicable because methods are not described; data is proprietary; and/or the data generation process has changed.
  - This raises the question: why do companies conduct research?
    - Companies may be motivated by the publicity and respectability gained
    - Individual employees may be trying to import academic research practices because of their skills and interests
- What now?
  - Extract the unique value from Big Data; don't try to replace older methods
  - Make algorithms public, or at least available to researchers for replication

>  Making money “without doing evil” (paraphrasing Google’s motto) is not enough when it is feasible to do so much good. It is also incumbent upon academia to build institutional models to facilitate collaborations with such big data projects—something that is too often missing now in universities.
