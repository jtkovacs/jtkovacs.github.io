<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="text/css" http-equiv="Content-Style-Type"/>
  <meta content="pandoc" name="generator"/>
  <title>
   jtck.github.io | data mining
  </title>
  <link href="../assets/styles/main.css" rel="stylesheet" type="text/css"/>
  <link href="../assets/styles/refs.css" rel="stylesheet" type="text/css"/>
 </head>
 <body>
  <p class="path">
   <a href="../pkb.html">
    pkb contents
   </a>
   &gt; data mining | just under 2054 words | updated 12/28/2017
  </p>
  <div class="TOC">
   <ul>
    <li>
     1.
     <a href="#what-is-data-mining">
      What is data mining?
     </a>
     <ul>
      <li>
       1.1.
       <a href="#business-applications-of-data-mining">
        Business applications of data mining
       </a>
       <ul>
        <li>
         1.1.1.
         <a href="#applications-by-technique">
          Applications by technique
         </a>
        </li>
        <li>
         1.1.2.
         <a href="#applications-by-industry">
          Applications by industry
         </a>
        </li>
       </ul>
      </li>
      <li>
       1.2.
       <a href="#doing-data-mining">
        Doing data mining
       </a>
       <ul>
        <li>
         1.2.1.
         <a href="#data-mining-processes">
          Data mining processes
         </a>
        </li>
        <li>
         1.2.2.
         <a href="#common-data-mining-pitfalls">
          Common data mining pitfalls
         </a>
        </li>
        <li>
         1.2.3.
         <a href="#data-mining-software">
          Data mining software
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     2.
     <a href="#data-mining-techniques">
      Data mining techniques
     </a>
     <ul>
      <li>
       2.1.
       <a href="#prediction">
        Prediction
       </a>
       <ul>
        <li>
         2.1.1.
         <a href="#regression">
          Regression
         </a>
        </li>
        <li>
         2.1.2.
         <a href="#classification">
          Classification
         </a>
         <ul>
          <li>
           2.1.2.1.
           <a href="#classification-versus-clustering">
            Classification versus clustering
           </a>
          </li>
          <li>
           2.1.2.2.
           <a href="#generic-classification-methodology">
            Generic classification methodology
           </a>
           <ul>
            <li>
             2.1.2.2.1.
             <a href="#training-approaches">
              Training approaches
             </a>
            </li>
           </ul>
          </li>
          <li>
           2.1.2.3.
           <a href="#evaluating-classification-models">
            Evaluating classification models
           </a>
           <ul>
            <li>
             2.1.2.3.1.
             <a href="#measuring-accuracy">
              Measuring accuracy
             </a>
            </li>
           </ul>
          </li>
          <li>
           2.1.2.4.
           <a href="#classification-techniques">
            Classification techniques
           </a>
           <ul>
            <li>
             2.1.2.4.1.
             <a href="#decision-tree-analysis">
              Decision tree analysis
             </a>
            </li>
            <li>
             2.1.2.4.2.
             <a href="#statistical-analysis">
              Statistical analysis
             </a>
            </li>
            <li>
             2.1.2.4.3.
             <a href="#neural-networks">
              Neural networks
             </a>
            </li>
            <li>
             2.1.2.4.4.
             <a href="#case-based-reasoning">
              Case-based reasoning
             </a>
            </li>
            <li>
             2.1.2.4.5.
             <a href="#bayesian-classifiers">
              Bayesian classifiers
             </a>
            </li>
            <li>
             2.1.2.4.6.
             <a href="#genetic-algorithms">
              Genetic algorithms
             </a>
            </li>
            <li>
             2.1.2.4.7.
             <a href="#rough-sets">
              Rough sets
             </a>
            </li>
           </ul>
          </li>
         </ul>
        </li>
       </ul>
      </li>
      <li>
       2.2.
       <a href="#association">
        Association
       </a>
       <ul>
        <li>
         2.2.1.
         <a href="#support-confidence">
          Support &amp; confidence
         </a>
        </li>
        <li>
         2.2.2.
         <a href="#apriori-algorithm">
          Apriori algorithm
         </a>
        </li>
       </ul>
      </li>
      <li>
       2.3.
       <a href="#clustering">
        Clustering
       </a>
       <ul>
        <li>
         2.3.1.
         <a href="#clustering-versus-classification">
          Clustering versus classification
         </a>
        </li>
        <li>
         2.3.2.
         <a href="#determining-optimal-number-of-clusters">
          Determining optimal number of clusters
         </a>
        </li>
        <li>
         2.3.3.
         <a href="#clustering-techniques">
          Clustering techniques
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     3.
     <a href="#sources">
      Sources
     </a>
     <ul>
      <li>
       3.1.
       <a href="#cited">
        Cited
       </a>
      </li>
      <li>
       3.2.
       <a href="#references">
        References
       </a>
      </li>
      <li>
       3.3.
       <a href="#read">
        Read
       </a>
      </li>
      <li>
       3.4.
       <a href="#unread">
        Unread
       </a>
      </li>
     </ul>
    </li>
   </ul>
  </div>
  <h1 id="what-is-data-mining">
   <a>
    1. What is data mining?
   </a>
  </h1>
  <p>
   Per Sharda et al. (2014), the field of data mining draws on
   <em>
    statistics, artificial intelligence and machine learning
   </em>
   to create data mining tools that facilitate the discovery of meaningful patterns in large BI datasets(see
   <a href="https://jtkovacs.github.io/refs/bi.html">
    notes on BI systems).
   </a>
   Adapted from Sharda et al. (2014, p. 157), there are three general patterns sought:
  </p>
  <table>
   <tr>
    <th colspan="2">
     Data Mining Task
    </th>
    <th>
     Learning Method
    </th>
    <th>
     Popular Algorithms
    </th>
   </tr>
   <tr>
    <td colspan="2">
     <strong>
      Prediction
     </strong>
     (forecasting Y based on Xs)
    </td>
    <td>
     Supervised
    </td>
    <td>
     Classification and regression trees, ANN, SVM, genetic algorithms
    </td>
   </tr>
   <tr>
    <td>
    </td>
    <td>
     <strong>
      Classification
     </strong>
    </td>
    <td>
     Supervised
    </td>
    <td>
     Decision trees, ANN/MLP, SVM, rough sets, genetic algorithms
    </td>
   </tr>
   <tr>
    <td>
    </td>
    <td>
     <strong>
      Regression
     </strong>
    </td>
    <td>
     Supervised
    </td>
    <td>
     Linear/nonlinear regression, regression trees, ANN/MLP, SVM
    </td>
   </tr>
   <tr>
    <td colspan="2">
     <strong>
      Association
     </strong>
     (relationship between X and Y)
    </td>
    <td>
     Unsupervised
    </td>
    <td>
     Apriori, OneR, ZeroR, Eclat
    </td>
   </tr>
   <tr>
    <td>
    </td>
    <td>
     <strong>
      Link analysis
     </strong>
    </td>
    <td>
     Unsupervised
    </td>
    <td>
     Expectation maximization, apriori algorithm, graph-based matching
    </td>
   </tr>
   <tr>
    <td>
    </td>
    <td>
     <strong>
      Sequence analysis
     </strong>
    </td>
    <td>
     Unsupervised
    </td>
    <td>
     Apriori algorithm, FP-growth technique
    </td>
   </tr>
   <tr>
    <td colspan="2">
     <strong>
      Clustering
     </strong>
     (breaking X into logical groups)
    </td>
    <td>
     Unsupervised
    </td>
    <td>
     K-means, ANN/SOM
    </td>
   </tr>
   <tr>
    <td>
    </td>
    <td>
     <strong>
      Outlier analysis
     </strong>
    </td>
    <td>
     Unsupervised
    </td>
    <td>
     K-means, expectation maximization (EM)
    </td>
   </tr>
  </table>
  <p>
   See
   <a href="https://jtkovacs.github.io/refs/statistics.html">
    notes on statistics
   </a>
   and
   <a href="https://jtkovacs.github.io/refs/machine-learning.html">
    notes on machine learning.
   </a>
  </p>
  <h2 id="business-applications-of-data-mining">
   <a>
    1.1. Business applications of data mining
   </a>
  </h2>
  <h3 id="applications-by-technique">
   <a>
    1.1.1. Applications by technique
   </a>
  </h3>
  <p>
   Per Sharda et al. (2014, pp. 172; 181; 183):
  </p>
  <table>
   <tr>
    <th>
     Clustering
    </th>
    <td style="text-align:left;">
     <ul>
      <li>
       "improve product placement on the sales floor ... and [coordinate] promotional pricing of products"
      </li>
      <li>
       identify credit fraud based on purchase combinations
      </li>
      <li>
       "sequentional patterns of services used by customers (checking account followed by savings account) can be used to identify other services they may be interested in (investment account)"
      </li>
      <li>
       "structure product bundles to maximize revenue"
      </li>
      <li>
       detect elevated medical risk as a combination of factors
      </li>
      <li>
       detect that "certain procedures at certain medical facilities can be tied to certain types of infection"
      </li>
     </ul>
    </td>
   </tr>
   <tr>
    <th>
     Association
    </th>
    <td style="text-align:left;">
     <ul>
      <li>
       "identify a classification scheme (e.g., types of customers)"
      </li>
      <li>
       "suggest statistical models to describe populations"
      </li>
      <li>
       "indicate rules for assigning new cases to classes for identification, tagging, and diagnostic purposes"
      </li>
      <li>
       "provide measures of definition, size, and change in what were previously broad concepts"
      </li>
      <li>
       "find typical cases to label and represent classes"
      </li>
      <li>
       "decrease the size and complexity of the problem space for other data mining methods"
      </li>
      <li>
       "identify outliers in a specific domain (i.e., rare-event detection)"
      </li>
     </ul>
    </td>
   </tr>
   <tr>
    <th>
     Prediction
    </th>
    <td style="text-align:left;">
     <ul>
      <li>
       credit approval
      </li>
      <li>
       store location
      </li>
      <li>
       target marketing
      </li>
      <li>
       fraud detection
      </li>
      <li>
       attrition
      </li>
     </ul>
    </td>
   </tr>
  </table>
  <h3 id="applications-by-industry">
   <a>
    1.1.2. Applications by industry
   </a>
  </h3>
  <p>
   Per Sharda et al. (2014, pp. 160-161):
  </p>
  <ul>
   <li>
    <strong>
     GENERIC
    </strong>
    (common across many domains)
    <ul>
     <li>
      customer profiling to identify most likely consumers for a given product, or most valuable customers to invest in
     </li>
     <li>
      churn analysis, identifying roots of customer or employee attrition
     </li>
     <li>
      identify and exploit seasonal trends
     </li>
     <li>
      yield management: "optimally price services to maximize revenues as a function of time-varying transactions"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Customer relationship management
    </strong>
    (CRM)
    <ul>
     <li>
      data comes from "product inquiries, sales, service requests, warranty calls, product reviews, social media connections", combined with "data on demographic and socioeconomic attributes"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Banking
    </strong>
    <ul>
     <li>
      automate loan applications (lololol)
     </li>
     <li>
      fraud detection
     </li>
     <li>
      forecasting cash flows across entities
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Retailing &amp; logistics
    </strong>
    <ul>
     <li>
      forecast demand, to
      <ul>
       <li>
        plan inventory levels
       </li>
       <li>
        optimize logistics
       </li>
      </ul>
     </li>
     <li>
      market basket analysis to "improve the store layout and optimize sales promotions"
     </li>
     <li>
      use RFID and sensory data to identify interesting product-specific insights
     </li>
     <li>
      recommendations
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Manufacturing &amp; production
    </strong>
    <ul>
     <li>
      RFID-enabled prediction of machinery failures, and "condition-based maintenance"
     </li>
     <li>
      improve product quality
     </li>
     <li>
      optimize manufacturing capacity
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Brokerage &amp; securities trading
    </strong>
    <ul>
     <li>
      forecast prices
     </li>
     <li>
      model impact of events on markets
     </li>
     <li>
      detect &amp; prevent fraud
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Insurance
    </strong>
    <ul>
     <li>
      "forecast claim amounts"
     </li>
     <li>
      "determine optimal rate plans"
     </li>
     <li>
      "identify and prevent incorrect claims payments and fraudulent activities"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Computer hardware &amp; software
    </strong>
    <ul>
     <li>
      predict hardware failures
     </li>
     <li>
      filter span and Web content
     </li>
     <li>
      identify software and network vulnerabilities
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Government &amp; defense
    </strong>
    <ul>
     <li>
      model behavior of opponent/s
     </li>
     <li>
      knowledge sharing
     </li>
     <li>
      "predict resource consumption for better planning and budgeting"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Homeland security &amp; law enforcement
    </strong>
    <ul>
     <li>
      "identify patterns of terrorist behaviors"
     </li>
     <li>
      "discover crime patterns (e.g., locations, timings, criminal behaviors, and other related attributes) to help solve criminal cases in a timely manner [???]"
     </li>
     <li>
      "predict and eliminate potential biological and chemical attacks to the nation's critical infrastructure by analyzing special-purpose sensory data"
     </li>
     <li>
      "identify and stop malicious attacks on critical information infrastructures"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Healthcare
    </strong>
    <ul>
     <li>
      "identify people without health insurance and the factors underlying this undersired phenomenon"
     </li>
     <li>
      "identify novel cost-benefit relationships between different treatments to develop more effective strategies"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Medicine
    </strong>
    <ul>
     <li>
      "identify novel patterns to improve survivability of patients with cancer"
     </li>
     <li>
      "predict success rates of organ transplantation patients to develop better donor-organ matching policies"
     </li>
     <li>
      "identify the functions of different gene in the human chromosome (known as genomics)"
     </li>
     <li>
      "discover the relationships between symptoms and illnesses to help medical professionals make informed and correct decisions"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Entertainment industry
    </strong>
    <ul>
     <li>
      recommend/auto-play features
     </li>
     <li>
      predict market reception of a movie, album, etc.
     </li>
     <li>
      forecasting to inform scheduling
     </li>
    </ul>
   </li>
  </ul>
  <h2 id="doing-data-mining">
   <a>
    1.2. Doing data mining
   </a>
  </h2>
  <h3 id="data-mining-processes">
   <a>
    1.2.1. Data mining processes
   </a>
  </h3>
  <p>
   Per Sharda et al. (2014):
  </p>
  <table>
   <tr>
    <th>
     CRISP-DM*
    </th>
    <th>
     SEMMA
    </th>
    <th>
     KDD**
    </th>
   </tr>
   <tr>
    <td>
     Business understanding
    </td>
    <td>
     Sample: "generate a representative sample of the data"
    </td>
    <td>
     Data selection
    </td>
   </tr>
   <tr>
    <td>
     Data understanding
    </td>
    <td>
     Explore: "visualization and basic description of the data"
    </td>
    <td>
     Data preprocessing
    </td>
   </tr>
   <tr>
    <td>
     Data preparation
    </td>
    <td>
     Modify: "select variables, transform variable representations"
    </td>
    <td>
     Data transformation
    </td>
   </tr>
   <tr>
    <td>
     Model building
    </td>
    <td>
     Model: "use a variety of statistical and machine learning model"
    </td>
    <td>
     Data mining
    </td>
   </tr>
   <tr>
    <td>
     Testing &amp; evaluation
    </td>
    <td rowspan="2">
     Assess: "evaluate the accuracy and usefulness of the models"
    </td>
    <td rowspan="2">
     Interpretation/evaluation
    </td>
   </tr>
   <tr>
    <td>
     Deployment
    </td>
   </tr>
  </table>
  <p>
   * Cross-Industry Standard Process for Data Mining, c. 1990s
  </p>
  <p>
   ** Knowledge Discovery in Databases, c. 1996
  </p>
  <h3 id="common-data-mining-pitfalls">
   <a>
    1.2.2. Common data mining pitfalls
   </a>
  </h3>
  <p>
   Per Sharda et al. (2014, p. 195):
  </p>
  <ul>
   <li>
    "Selecting the wrong problem for data mining.
   </li>
   <li>
    Ignoring what your sponsor thinks data mining is and what it really can and cannot do.
   </li>
   <li>
    Leaving insufficient time for data preparation. It takes more effort than is generally understood.
   </li>
   <li>
    Looking only at aggregated results and not at individual records ...
   </li>
   <li>
    Being sloppy about keeping track of the data mining procedure and results.
   </li>
   <li>
    Ignoring suspicious findings and quickly moving on.
   </li>
   <li>
    Running mining algorithms repeatedly and blindly ...
   </li>
   <li>
    Believing everything you are told about the data.
   </li>
   <li>
    Believing everything you are told about your own data mining analysis [????]
   </li>
   <li>
    Measuring your results differently from the way your sponsor measures them."
   </li>
  </ul>
  <h3 id="data-mining-software">
   <a>
    1.2.3. Data mining software
   </a>
  </h3>
  <p>
   Per Sharda et al. (2014, p. 187), some commercial tools:
  </p>
  <ul>
   <li>
    IBM SPSS Modeler
   </li>
   <li>
    SAS Enterprise Miner
   </li>
   <li>
    Statistica
   </li>
   <li>
    Inteligent Miner
   </li>
   <li>
    PolyAnalyst
   </li>
   <li>
    CART, MARS, TreeNet, RandomForest (Saleford Systems)
   </li>
   <li>
    Insightful Miner
   </li>
   <li>
    XL Miner
   </li>
   <li>
    KXEN
   </li>
   <li>
    GhostMiner
   </li>
   <li>
    Microsoft SQL Server Data Mining
   </li>
   <li>
    Knowledge Miner
   </li>
   <li>
    Teradata Warehouse Miner
   </li>
   <li>
    Oracle Data Mining
   </li>
   <li>
    Fair Isaac Business Science
   </li>
   <li>
    DeltaMaster
   </li>
   <li>
    iData Analyzer
   </li>
   <li>
    Orange Data Mining Tool
   </li>
   <li>
    Zementis Predictive Analytics
   </li>
  </ul>
  <p>
   Also, they cite a poll from KDNuggets.com (most to least popular):
  </p>
  <ul>
   <li>
    R
   </li>
   <li>
    Excel
   </li>
   <li>
    Rapid-I RapidMiner
   </li>
   <li>
    KNIME
   </li>
   <li>
    Weka/Pentaho
   </li>
   <li>
    StatSoft Statistica
   </li>
   <li>
    SAS
   </li>
   <li>
    Rapid-I RapidAnalytics
   </li>
   <li>
    MATLAB
   </li>
   <li>
    IMB SPSS Statistics
   </li>
   <li>
    IBM SPSS Modeler
   </li>
   <li>
    Orange
   </li>
   <li>
    Microsoft SQL Server
   </li>
   <li>
    Other free software
   </li>
   <li>
    TIBCO Spotfire/S+/Miner
   </li>
   <li>
    Tableau
   </li>
   <li>
    Oracle Data Miner
   </li>
   <li>
    Other commercial software
   </li>
   <li>
    ...
   </li>
  </ul>
  <h1 id="data-mining-techniques">
   <a>
    2. Data mining techniques
   </a>
  </h1>
  <h2 id="prediction">
   <a>
    2.1. Prediction
   </a>
  </h2>
  <p>
   Per Sharda et al. (2014, p. 172), "classification learns patterns from past data (a set of information---traits, variables, features---on characteristics of the previously labeled items, objects, or events) in order to place new instances (with unknown labels) into their respective groups or classes. If what is being predicted is a class label (e.g., 'sunny, 'rainy', or 'cloudy') the prediction problem is called a classification, whereas if it is a numeric value (e.g., temperature such as 68°F), the prediction problem is called a regression".
  </p>
  <h3 id="regression">
   <a>
    2.1.1. Regression
   </a>
  </h3>
  <h3 id="classification">
   <a>
    2.1.2. Classification
   </a>
  </h3>
  <p>
   Per Sharda et al. (2014, p. 172), "classification learns patterns from past data (a set of information---traits, variables, features---on characteristics of the previously labeled items, objects, or events) in order to place new instances (with unknown labels) into their respective groups or classes."
  </p>
  <h4 id="classification-versus-clustering">
   <a>
    2.1.2.1. Classification versus clustering
   </a>
  </h4>
  <p>
   Per Sharda et al. (2014, p. 172), "Even though clustering ... can also be used to determine groups (or class memberships) of things, there is a significant difference between the two. Classification learns the function between the characteristics of things (i.e., [their] independent variables) and their membership (i.e., output variable) through a supervised learning process where both types (input and output) of variables are presented to the algorithm; in clustering, the membership of the objects is learned through an unsupervised learning process where only the input variables are presented to the algorithm. Unlike classification, clustering does not habe a supervising (or controlling) mechanism that enforces the learning process; instead, clustering algorithms use one or more heuristics (e.g., multidimensional distance measure) to discover natural groupings of objects."
  </p>
  <h4 id="generic-classification-methodology">
   <a>
    2.1.2.2. Generic classification methodology
   </a>
  </h4>
  <p>
   Per Sharda et al. (2014):
  </p>
  <ol style="list-style-type: decimal">
   <li>
    Model development AKA training: "a collection of input data, including the actual class labels, is used ... [and] the model is trained"
   </li>
   <li>
    Model testing: "the model is tested against the holdout sample for accuracy assessment ..."
   </li>
   <li>
    Model deployment: "... and eventually deployed for actual use"
   </li>
  </ol>
  <h5 id="training-approaches">
   <a>
    2.1.2.2.1. Training approaches
   </a>
  </h5>
  <ul>
   <li>
    Simple split
   </li>
   <li>
    k-fold cross-validation AKA rotation estimation
   </li>
   <li>
    leave-one-out
   </li>
   <li>
    bootstrapping
   </li>
   <li>
    jackknifing
   </li>
  </ul>
  <h4 id="evaluating-classification-models">
   <a>
    2.1.2.3. Evaluating classification models
   </a>
  </h4>
  <p>
   Per Sharda et al. (2014, pp. 172-173):
  </p>
  <ul>
   <li>
    <strong>
     Predictive accuracy
    </strong>
    (most common): "The model's ability to correctly predict the class label of new or previously unseen data"
   </li>
   <li>
    <strong>
     Speed:
    </strong>
    "The computational costs incolced in generating and using the model, where faster is deemed to be better"
   </li>
   <li>
    <strong>
     Scalability:
    </strong>
    "The ability to construct a prediction model efficiently given a rather large amount of data"
   </li>
   <li>
    <strong>
     Interpretability:
    </strong>
    "The level of understanding and insight provided by the model (e.g., how and/or what the model concludes on certain predictions)"
   </li>
  </ul>
  <h5 id="measuring-accuracy">
   <a>
    2.1.2.3.1. Measuring accuracy
   </a>
  </h5>
  <p>
   From Sharda et al. (2014, pp. 173-174), the universally-known
   <strong>
    confusion matrix
   </strong>
   (AKA classification matrix, AKA contingency table) for a two-class classification problem:
  </p>
  <table>
   <tr>
    <th colspan="2" rowspan="2">
    </th>
    <th colspan="2">
     True Class
    </th>
   </tr>
   <tr>
    <th>
     Positive
    </th>
    <th>
     Negative
    </th>
   </tr>
   <tr>
    <th rowspan="2">
     Predicted Class
    </th>
    <th>
     Positive
    </th>
    <td>
     True positive count (TP)
    </td>
    <td>
     False positive count (FP)
    </td>
   </tr>
   <tr>
    <th>
     Negative
    </th>
    <td>
     False negative count (FN)
    </td>
    <td>
     True negative count (TN)
    </td>
   </tr>
  </table>
  <p>
   Common accuracy metrics:
  </p>
  <table>
   <thead>
    <tr class="header">
     <th align="left">
      Formula
     </th>
     <th align="left">
      Description
     </th>
    </tr>
   </thead>
   <tbody>
    <tr class="odd">
     <td align="left">
      TRUE POSITIVE RATE = RECALL = TP/(TP+FN)
     </td>
     <td align="left">
      "The ratio of correctly classified positives divided by the sum of correctly classified positives and incorrectly classified negatives"
     </td>
    </tr>
    <tr class="even">
     <td align="left">
      TRUE NEGATIVE RATE = TN/(TN+FP)
     </td>
     <td align="left">
      "The ratio of correctly classified negatives divided by the total negative count (i.e., false alarm rate)" i.e., the sum of correctly classified negatives and incorrectly classified positives"
     </td>
    </tr>
    <tr class="odd">
     <td align="left">
      ACCURACY = (TP+TN)/(TP+TN+FP+FN)
     </td>
     <td align="left">
      "The ratio of correctly classified instances (positives and negatives) divided by the total number of instances"
     </td>
    </tr>
    <tr class="even">
     <td align="left">
      PRECISION = TP/(TP+FP)
     </td>
     <td align="left">
      "The ratio of correctly classified positives divided by the sum of correctly classified positives and incorrectly classified positives"
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   "The
   <strong>
    area under the ROC curve
   </strong>
   is a graphical assessment technique where the true positive rate is plotted on the y-axis and the false positive rate is plotted on the x-axis. The area under the ROC curve determines the accuracy measure of a classifier: A value of 1 indicates a perfect classifier whereas 0.5 indicates no better than random chance" (Sharda et al., 2014, p. 175).
  </p>
  <p>
   Accuracy metrics for classification problems with more than two classes:
  </p>
  <ul>
   <li>
    Per class accuracy rates:
    <em>
     True classification rate
     <sub>
      i
     </sub>
     = (True classification)
     <sub>
      i
     </sub>
     / ∑
     <sub>
      i=1
     </sub>
     <sup>
      n
     </sup>
     (False classification)
     <sub>
      i
     </sub>
    </em>
   </li>
   <li>
    <em>
     (Overall classifier accuracy)
     <sub>
      i
     </sub>
     = ∑
     <sub>
      i=1
     </sub>
     <sup>
      n
     </sup>
     (True classification)
     <sub>
      i
     </sub>
     / Total number of cases
    </em>
   </li>
  </ul>
  <h4 id="classification-techniques">
   <a>
    2.1.2.4. Classification techniques
   </a>
  </h4>
  <p>
   Per Sharda et al. (2014, pp. 175-176):
  </p>
  <h5 id="decision-tree-analysis">
   <a>
    2.1.2.4.1. Decision tree analysis
   </a>
  </h5>
  <h5 id="statistical-analysis">
   <a>
    2.1.2.4.2. Statistical analysis
   </a>
  </h5>
  <h5 id="neural-networks">
   <a>
    2.1.2.4.3. Neural networks
   </a>
  </h5>
  <h5 id="case-based-reasoning">
   <a>
    2.1.2.4.4. Case-based reasoning
   </a>
  </h5>
  <h5 id="bayesian-classifiers">
   <a>
    2.1.2.4.5. Bayesian classifiers
   </a>
  </h5>
  <h5 id="genetic-algorithms">
   <a>
    2.1.2.4.6. Genetic algorithms
   </a>
  </h5>
  <h5 id="rough-sets">
   <a>
    2.1.2.4.7. Rough sets
   </a>
  </h5>
  <h2 id="association">
   <a>
    2.2. Association
   </a>
  </h2>
  <h3 id="support-confidence">
   <a>
    2.2.1. Support &amp; confidence
   </a>
  </h3>
  <h3 id="apriori-algorithm">
   <a>
    2.2.2. Apriori algorithm
   </a>
  </h3>
  <h2 id="clustering">
   <a>
    2.3. Clustering
   </a>
  </h2>
  <h3 id="clustering-versus-classification">
   <a>
    2.3.1. Clustering versus classification
   </a>
  </h3>
  <p>
   Per Sharda et al. (2014, p. 172), "Even though clustering ... can also be used to determine groups (or class memberships) of things, there is a significant difference between the two. Classification learns the function between the characteristics of things (i.e., [their] independent variables) and their membership (i.e., output variable) through a supervised learning process where both types (input and output) of variables are presented to the algorithm; in clustering, the membership of the objects is learned through an unsupervised learning process where only the input variables are presented to the algorithm. Unlike classification, clustering does not habe a supervising (or controlling) mechanism that enforces the learning process; instead, clustering algorithms use one or more heuristics (e.g., multidimensional distance measure) to discover natural groupings of objects."
  </p>
  <h3 id="determining-optimal-number-of-clusters">
   <a>
    2.3.2. Determining optimal number of clusters
   </a>
  </h3>
  <h3 id="clustering-techniques">
   <a>
    2.3.3. Clustering techniques
   </a>
  </h3>
  <p>
   Divisive vs. agglomerative
  </p>
  <p>
   Statistical (non/hierarchical) vs neural networks vs fuzzy logic vs genetic algorithms
  </p>
  <p>
   Distance measures
  </p>
  <p>
   k-means
  </p>
  <h1 id="sources">
   <a>
    3. Sources
   </a>
  </h1>
  <h2 id="cited">
   <a>
    3.1. Cited
   </a>
  </h2>
  <p>
   Sharda, R., Delen, D., &amp; Turban, E. (2014).
   <em>
    Business intelligence: A managerial perspective on analytics
   </em>
   (3rd ed.). New York City, NY: Pearson.
  </p>
  <h2 id="references">
   <a>
    3.2. References
   </a>
  </h2>
  <h2 id="read">
   <a>
    3.3. Read
   </a>
  </h2>
  <h2>
   <a name="3.4.-unread">
    3.4. Unread
   </a>
  </h2>
 </body>
</html>
