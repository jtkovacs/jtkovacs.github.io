<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="text/css" http-equiv="Content-Style-Type"/>
  <meta content="pandoc" name="generator"/>
  <title>
   jtck.github.io | data mining
  </title>
  <link href="../assets/styles/main.css" rel="stylesheet" type="text/css"/>
  <link href="../assets/styles/refs.css" rel="stylesheet" type="text/css"/>
 </head>
 <body>
  <p class="path">
   <a href="../pkb.html">
    pkb contents
   </a>
   &gt; data mining | just under 1246 words | updated 12/28/2017
  </p>
  <div class="TOC">
   <ul>
    <li>
     1.
     <a href="#what-is-data-mining">
      What is data mining?
     </a>
     <ul>
      <li>
       1.1.
       <a href="#business-applications-of-data-mining">
        Business applications of data mining
       </a>
       <ul>
        <li>
         1.1.1.
         <a href="#applications-by-technique">
          Applications by technique
         </a>
        </li>
        <li>
         1.1.2.
         <a href="#applications-by-industry">
          Applications by industry
         </a>
        </li>
       </ul>
      </li>
      <li>
       1.2.
       <a href="#doing-data-mining">
        Doing data mining
       </a>
       <ul>
        <li>
         1.2.1.
         <a href="#data-mining-processes">
          Data mining processes
         </a>
        </li>
        <li>
         1.2.2.
         <a href="#common-data-mining-pitfalls">
          Common data mining pitfalls
         </a>
        </li>
        <li>
         1.2.3.
         <a href="#data-mining-software">
          Data mining software
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     2.
     <a href="#prediction">
      Prediction
     </a>
     <ul>
      <li>
       2.1.
       <a href="#regression">
        Regression
       </a>
      </li>
      <li>
       2.2.
       <a href="#classification">
        Classification
       </a>
       <ul>
        <li>
         2.2.1.
         <a href="#estimating-the-true-accuracy-of-classification-models">
          Estimating the true accuracy of classification models
         </a>
        </li>
        <li>
         2.2.2.
         <a href="#classification-techniques">
          Classification techniques
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     3.
     <a href="#association">
      Association
     </a>
     <ul>
      <li>
       3.1.
       <a href="#support-confidence">
        Support &amp; confidence
       </a>
      </li>
      <li>
       3.2.
       <a href="#apriori-algorithm">
        Apriori algorithm
       </a>
      </li>
     </ul>
    </li>
    <li>
     4.
     <a href="#clustering">
      Clustering
     </a>
     <ul>
      <li>
       4.1.
       <a href="#determining-optimal-#-of-clusters">
        Determining optimal # of clusters
       </a>
      </li>
      <li>
       4.2.
       <a href="#clustering-techniques">
        Clustering techniques
       </a>
      </li>
     </ul>
    </li>
    <li>
     5.
     <a href="#sources">
      Sources
     </a>
     <ul>
      <li>
       5.1.
       <a href="#cited">
        Cited
       </a>
      </li>
      <li>
       5.2.
       <a href="#references">
        References
       </a>
      </li>
      <li>
       5.3.
       <a href="#read">
        Read
       </a>
      </li>
      <li>
       5.4.
       <a href="#unrea">
        Unrea
       </a>
      </li>
     </ul>
    </li>
   </ul>
  </div>
  <h1 id="what-is-data-mining">
   <a>
    1. What is data mining?
   </a>
  </h1>
  <p>
   Per Sharda et al. (2014), the field of data mining draws on
   <em>
    statistics, artificial intelligence and machine learning
   </em>
   to create data mining tools that facilitate the discovery of meaningful patterns in large BI datasets(see
   <a href="https://jtkovacs.github.io/refs/bi.html">
    notes on BI systems).
   </a>
   Adapted from Sharda et al. (2014, p. 157), there are three general patterns sought:
  </p>
  <table>
   <tr>
    <th colspan="2">
     Data Mining Task
    </th>
    <th>
     Learning Method
    </th>
    <th>
     Popular Algorithms
    </th>
   </tr>
   <tr>
    <td colspan="2">
     <strong>
      Prediction
     </strong>
     (forecasting Y based on Xs)
    </td>
    <td>
     Supervised
    </td>
    <td>
     Classification and regression trees, ANN, SVM, genetic algorithms
    </td>
   </tr>
   <tr>
    <td>
    </td>
    <td>
     <strong>
      Classification
     </strong>
    </td>
    <td>
     Supervised
    </td>
    <td>
     Decision trees, ANN/MLP, SVM, rough sets, genetic algorithms
    </td>
   </tr>
   <tr>
    <td>
    </td>
    <td>
     <strong>
      Regression
     </strong>
    </td>
    <td>
     Supervised
    </td>
    <td>
     Linear/nonlinear regression, regression trees, ANN/MLP, SVM
    </td>
   </tr>
   <tr>
    <td colspan="2">
     <strong>
      Association
     </strong>
     (relationship between X and Y)
    </td>
    <td>
     Unsupervised
    </td>
    <td>
     Apriori, OneR, ZeroR, Eclat
    </td>
   </tr>
   <tr>
    <td>
    </td>
    <td>
     <strong>
      Link analysis
     </strong>
    </td>
    <td>
     Unsupervised
    </td>
    <td>
     Expectation maximization, apriori algorithm, graph-based matching
    </td>
   </tr>
   <tr>
    <td>
    </td>
    <td>
     <strong>
      Sequence analysis
     </strong>
    </td>
    <td>
     Unsupervised
    </td>
    <td>
     Apriori algorithm, FP-growth technique
    </td>
   </tr>
   <tr>
    <td colspan="2">
     <strong>
      Clustering
     </strong>
     (breaking X into logical groups)
    </td>
    <td>
     Unsupervised
    </td>
    <td>
     K-means, ANN/SOM
    </td>
   </tr>
   <tr>
    <td>
    </td>
    <td>
     <strong>
      Outlier analysis
     </strong>
    </td>
    <td>
     Unsupervised
    </td>
    <td>
     K-means, expectation maximization (EM)
    </td>
   </tr>
  </table>
  <p>
   See
   <a href="https://jtkovacs.github.io/refs/statistics.html">
    notes on statistics
   </a>
   and
   <a href="https://jtkovacs.github.io/refs/machine-learning.html">
    notes on machine learning.
   </a>
  </p>
  <h2 id="business-applications-of-data-mining">
   <a>
    1.1. Business applications of data mining
   </a>
  </h2>
  <h3 id="applications-by-technique">
   <a>
    1.1.1. Applications by technique
   </a>
  </h3>
  <p>
   Per Sharda et al. (2015, pp. 172; 181; 183):
  </p>
  <table>
   <tr>
    <th>
     Clustering
    </th>
    <td style="text-align:left;">
     <ul>
      <li>
       "improve product placement on the sales floor ... and [coordinate] promotional pricing of products"
      </li>
      <li>
       identify credit fraud based on purchase combinations
      </li>
      <li>
       "sequentional patterns of services used by customers (checking account followed by savings account) can be used to identify other services they may be interested in (investment account)"
      </li>
      <li>
       "structure product bundles to maximize revenue"
      </li>
      <li>
       detect elevated medical risk as a combination of factors
      </li>
      <li>
       detect that "certain procedures at certain medical facilities can be tied to certain types of infection"
      </li>
     </ul>
    </td>
   </tr>
   <tr>
    <th>
     Association
    </th>
    <td style="text-align:left;">
     <ul>
      <li>
       "identify a classification scheme (e.g., types of customers)"
      </li>
      <li>
       "suggest statistical models to describe populations"
      </li>
      <li>
       "indicate rules for assigning new cases to classes for identification, tagging, and diagnostic purposes"
      </li>
      <li>
       "provide measures of definition, size, and change in what were previously broad concepts"
      </li>
      <li>
       "find typical cases to label and represent classes"
      </li>
      <li>
       "decrease the size and complexity of the problem space for other data mining methods"
      </li>
      <li>
       "identify outliers in a specific domain (i.e., rare-event detection)"
      </li>
     </ul>
    </td>
   </tr>
   <tr>
    <th>
     Prediction
    </th>
    <td style="text-align:left;">
     <ul>
      <li>
       credit approval
      </li>
      <li>
       store location
      </li>
      <li>
       target marketing
      </li>
      <li>
       fraud detection
      </li>
      <li>
       attrition
      </li>
     </ul>
    </td>
   </tr>
  </table>
  <h3 id="applications-by-industry">
   <a>
    1.1.2. Applications by industry
   </a>
  </h3>
  <p>
   Per Sharda et al. (2014, pp. 160-161):
  </p>
  <ul>
   <li>
    <strong>
     GENERIC
    </strong>
    (common across many domains)
    <ul>
     <li>
      customer profiling to identify most likely consumers for a given product, or most valuable customers to invest in
     </li>
     <li>
      churn analysis, identifying roots of customer or employee attrition
     </li>
     <li>
      identify and exploit seasonal trends
     </li>
     <li>
      yield management: "optimally price services to maximize revenues as a function of time-varying transactions"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Customer relationship management
    </strong>
    (CRM)
    <ul>
     <li>
      data comes from "product inquiries, sales, service requests, warranty calls, product reviews, social media connections", combined with "data on demographic and socioeconomic attributes"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Banking
    </strong>
    <ul>
     <li>
      automate loan applications (lololol)
     </li>
     <li>
      fraud detection
     </li>
     <li>
      forecasting cash flows across entities
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Retailing &amp; logistics
    </strong>
    <ul>
     <li>
      forecast demand, to
      <ul>
       <li>
        plan inventory levels
       </li>
       <li>
        optimize logistics
       </li>
      </ul>
     </li>
     <li>
      market basket analysis to "improve the store layout and optimize sales promotions"
     </li>
     <li>
      use RFID and sensory data to identify interesting product-specific insights
     </li>
     <li>
      recommendations
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Manufacturing &amp; production
    </strong>
    <ul>
     <li>
      RFID-enabled prediction of machinery failures, and "condition-based maintenance"
     </li>
     <li>
      improve product quality
     </li>
     <li>
      optimize manufacturing capacity
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Brokerage &amp; securities trading
    </strong>
    <ul>
     <li>
      forecast prices
     </li>
     <li>
      model impact of events on markets
     </li>
     <li>
      detect &amp; prevent fraud
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Insurance
    </strong>
    <ul>
     <li>
      "forecast claim amounts"
     </li>
     <li>
      "determine optimal rate plans"
     </li>
     <li>
      "identify and prevent incorrect claims payments and fraudulent activities"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Computer hardware &amp; software
    </strong>
    <ul>
     <li>
      predict hardware failures
     </li>
     <li>
      filter span and Web content
     </li>
     <li>
      identify software and network vulnerabilities
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Government &amp; defense
    </strong>
    <ul>
     <li>
      model behavior of opponent/s
     </li>
     <li>
      knowledge sharing
     </li>
     <li>
      "predict resource consumption for better planning and budgeting"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Homeland security &amp; law enforcement
    </strong>
    <ul>
     <li>
      "identify patterns of terrorist behaviors"
     </li>
     <li>
      "discover crime patterns (e.g., locations, timings, criminal behaviors, and other related attributes) to help solve criminal cases in a timely manner [???]"
     </li>
     <li>
      "predict and eliminate potential biological and chemical attacks to the nation's critical infrastructure by analyzing special-purpose sensory data"
     </li>
     <li>
      "identify and stop malicious attacks on critical information infrastructures"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Healthcare
    </strong>
    <ul>
     <li>
      "identify people without health insurance and the factors underlying this undersired phenomenon"
     </li>
     <li>
      "identify novel cost-benefit relationships between different treatments to develop more effective strategies"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Medicine
    </strong>
    <ul>
     <li>
      "identify novel patterns to improve survivability of patients with cancer"
     </li>
     <li>
      "predict success rates of organ transplantation patients to develop better donor-organ matching policies"
     </li>
     <li>
      "identify the functions of different gene in the human chromosome (known as genomics)"
     </li>
     <li>
      "discover the relationships between symptoms and illnesses to help medical professionals make informed and correct decisions"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Entertainment industry
    </strong>
    <ul>
     <li>
      recommend/auto-play features
     </li>
     <li>
      predict market reception of a movie, album, etc.
     </li>
     <li>
      forecasting to inform scheduling
     </li>
    </ul>
   </li>
  </ul>
  <h2 id="doing-data-mining">
   <a>
    1.2. Doing data mining
   </a>
  </h2>
  <h3 id="data-mining-processes">
   <a>
    1.2.1. Data mining processes
   </a>
  </h3>
  <p>
   Per Sharda et al. (2014):
  </p>
  <table>
   <tr>
    <th>
     CRISP-DM*
    </th>
    <th>
     SEMMA
    </th>
    <th>
     KDD**
    </th>
   </tr>
   <tr>
    <td>
     Business understanding
    </td>
    <td>
     Sample: "generate a representative sample of the data"
    </td>
    <td>
     Data selection
    </td>
   </tr>
   <tr>
    <td>
     Data understanding
    </td>
    <td>
     Explore: "visualization and basic description of the data"
    </td>
    <td>
     Data preprocessing
    </td>
   </tr>
   <tr>
    <td>
     Data preparation
    </td>
    <td>
     Modify: "select variables, transform variable representations"
    </td>
    <td>
     Data transformation
    </td>
   </tr>
   <tr>
    <td>
     Model building
    </td>
    <td>
     Model: "use a variety of statistical and machine learning model"
    </td>
    <td>
     Data mining
    </td>
   </tr>
   <tr>
    <td>
     Testing &amp; evaluation
    </td>
    <td rowspan="2">
     Assess: "evaluate the accuracy and usefulness of the models"
    </td>
    <td rowspan="2">
     Interpretation/evaluation
    </td>
   </tr>
   <tr>
    <td>
     Deployment
    </td>
   </tr>
  </table>
  <p>
   * Cross-Industry Standard Process for Data Mining, c. 1990s
  </p>
  <p>
   ** Knowledge Discovery in Databases, c. 1996
  </p>
  <h3 id="common-data-mining-pitfalls">
   <a>
    1.2.2. Common data mining pitfalls
   </a>
  </h3>
  <p>
   Per Sharda et al. (2015, p. 195):
  </p>
  <ul>
   <li>
    "Selecting the wrong problem for data mining.
   </li>
   <li>
    Ignoring what your sponsor thinks data mining is and what it really can and cannot do.
   </li>
   <li>
    Leaving insufficient time for data preparation. It takes more effort than is generally understood.
   </li>
   <li>
    Looking only at aggregated results and not at individual records ...
   </li>
   <li>
    Being sloppy about keeping track of the data mining procedure and results.
   </li>
   <li>
    Ignoring suspicious findings and quickly moving on.
   </li>
   <li>
    Running mining algorithms repeatedly and blindly ...
   </li>
   <li>
    Believing everything you are told about the data.
   </li>
   <li>
    Believing everything you are told about your own data mining analysis [????]
   </li>
   <li>
    Measuring your results differently from the way your sponsor measures them."
   </li>
  </ul>
  <h3 id="data-mining-software">
   <a>
    1.2.3. Data mining software
   </a>
  </h3>
  <p>
   Per Sharda et al. (2015, p. 187), some commercial tools:
  </p>
  <ul>
   <li>
    IBM SPSS Modeler
   </li>
   <li>
    SAS Enterprise Miner
   </li>
   <li>
    Statistica
   </li>
   <li>
    Inteligent Miner
   </li>
   <li>
    PolyAnalyst
   </li>
   <li>
    CART, MARS, TreeNet, RandomForest (Saleford Systems)
   </li>
   <li>
    Insightful Miner
   </li>
   <li>
    XL Miner
   </li>
   <li>
    KXEN
   </li>
   <li>
    GhostMiner
   </li>
   <li>
    Microsoft SQL Server Data Mining
   </li>
   <li>
    Knowledge Miner
   </li>
   <li>
    Teradata Warehouse Miner
   </li>
   <li>
    Oracle Data Mining
   </li>
   <li>
    Fair Isaac Business Science
   </li>
   <li>
    DeltaMaster
   </li>
   <li>
    iData Analyzer
   </li>
   <li>
    Orange Data Mining Tool
   </li>
   <li>
    Zementis Predictive Analytics
   </li>
  </ul>
  <p>
   Also, they cite a poll from KDNuggets.com (most to least popular):
  </p>
  <ul>
   <li>
    R
   </li>
   <li>
    Excel
   </li>
   <li>
    Rapid-I RapidMiner
   </li>
   <li>
    KNIME
   </li>
   <li>
    Weka/Pentaho
   </li>
   <li>
    StatSoft Statistica
   </li>
   <li>
    SAS
   </li>
   <li>
    Rapid-I RapidAnalytics
   </li>
   <li>
    MATLAB
   </li>
   <li>
    IMB SPSS Statistics
   </li>
   <li>
    IBM SPSS Modeler
   </li>
   <li>
    Orange
   </li>
   <li>
    Microsoft SQL Server
   </li>
   <li>
    Other free software
   </li>
   <li>
    TIBCO Spotfire/S+/Miner
   </li>
   <li>
    Tableau
   </li>
   <li>
    Oracle Data Miner
   </li>
   <li>
    Other commercial software
   </li>
   <li>
    ...
   </li>
  </ul>
  <h1 id="prediction">
   <a>
    2. Prediction
   </a>
  </h1>
  <h2 id="regression">
   <a>
    2.1. Regression
   </a>
  </h2>
  <h2 id="classification">
   <a>
    2.2. Classification
   </a>
  </h2>
  <h3 id="estimating-the-true-accuracy-of-classification-models">
   <a>
    2.2.1. Estimating the true accuracy of classification models
   </a>
  </h3>
  <p>
   per-class
  </p>
  <p>
   overall
  </p>
  <p>
   confusion matrix
  </p>
  <p>
   metrics
  </p>
  <p>
   Measuring accuracy
  </p>
  <p>
   Estimation methods
  </p>
  <ul>
   <li>
    Simple split
   </li>
   <li>
    k-fold cross-validation
   </li>
   <li>
    leave-one-out
   </li>
   <li>
    bootstrapping
   </li>
   <li>
    jackknifing
   </li>
   <li>
    area under the ROC curve
   </li>
  </ul>
  <h3 id="classification-techniques">
   <a>
    2.2.2. Classification techniques
   </a>
  </h3>
  <p>
   Decision tree analysis
  </p>
  <p>
   Statistical analysis
  </p>
  <p>
   Neural networks
  </p>
  <p>
   Case-based reasoning
  </p>
  <p>
   Bayesian classifiers
  </p>
  <p>
   Genetic algorithms
  </p>
  <p>
   Rough sets
  </p>
  <h1 id="association">
   <a>
    3. Association
   </a>
  </h1>
  <h2 id="support-confidence">
   <a>
    3.1. Support &amp; confidence
   </a>
  </h2>
  <h2 id="apriori-algorithm">
   <a>
    3.2. Apriori algorithm
   </a>
  </h2>
  <h1 id="clustering">
   <a>
    4. Clustering
   </a>
  </h1>
  <h2 id="determining-optimal-of-clusters">
   <a>
    4.1. Determining optimal # of clusters
   </a>
  </h2>
  <h2 id="clustering-techniques">
   <a>
    4.2. Clustering techniques
   </a>
  </h2>
  <p>
   Divisive vs. agglomerative
  </p>
  <p>
   Statistical (non/hierarchical) vs neural networks vs fuzzy logic vs genetic algorithms
  </p>
  <p>
   Distance measures
  </p>
  <p>
   k-means
  </p>
  <h1 id="sources">
   <a>
    5. Sources
   </a>
  </h1>
  <h2 id="cited">
   <a>
    5.1. Cited
   </a>
  </h2>
  <p>
   Sharda, R., Delen, D., &amp; Turban, E. (2014).
   <em>
    Business intelligence: A managerial perspective on analytics
   </em>
   (3rd ed.). New York City, NY: Pearson.
  </p>
  <h2 id="references">
   <a>
    5.2. References
   </a>
  </h2>
  <h2 id="read">
   <a>
    5.3. Read
   </a>
  </h2>
  <h2>
   <a name="5.4.-unread">
    5.4. Unread
   </a>
  </h2>
 </body>
</html>
