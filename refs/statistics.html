<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="text/css" http-equiv="Content-Style-Type"/>
  <meta content="pandoc" name="generator"/>
  <title>
   jtkovacs.github.io | statistics
  </title>
  <link href="../assets/styles/main.css" rel="stylesheet" type="text/css"/>
  <style type="text/css">
   div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <link href="../assets/styles/refs.css" rel="stylesheet" type="text/css"/>
 </head>
 <body>
  <p class="path">
   <a href="../pkb.html">
    pkb contents
   </a>
   &gt; statistics | just under 1235 words | updated 05/21/2017
  </p>
  <div class="TOC">
   <ul>
    <li>
     1.
     <a href="#probability-statistics">
      Probability &amp; statistics
     </a>
     <ul>
      <li>
       1.1.
       <a href="#notes">
        Notes
       </a>
      </li>
      <li>
       1.2.
       <a href="#...-in-r">
        ... in R
       </a>
      </li>
      <li>
       1.3.
       <a href="#...-in-python">
        ... in Python
       </a>
      </li>
      <li>
       1.4.
       <a href="#sources">
        Sources
       </a>
       <ul>
        <li>
         1.4.1.
         <a href="#references">
          References
         </a>
        </li>
        <li>
         1.4.2.
         <a href="#read">
          Read
         </a>
        </li>
        <li>
         1.4.3.
         <a href="#unread">
          Unread
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     2.
     <a href="#linear-algebra">
      Linear Algebra
     </a>
    </li>
    <li>
     3.
     <a href="#relationships-trends">
      Relationships &amp; Trends
     </a>
    </li>
    <li>
     4.
     <a href="#hypothesis-ab-testing">
      Hypothesis &amp; A/B Testing
     </a>
     <ul>
      <li>
       4.1.
       <a href="#references">
        References
       </a>
      </li>
      <li>
       4.2.
       <a href="#read">
        Read
       </a>
      </li>
      <li>
       4.3.
       <a href="#unread">
        Unread
       </a>
      </li>
     </ul>
    </li>
   </ul>
  </div>
  <h1 id="probability-statistics">
   <a>
    1. Probability &amp; statistics
   </a>
  </h1>
  <h2 id="notes">
   <a>
    1.1. Notes
   </a>
  </h2>
  <ul>
   <li>
    https://docs.google.com/document/d/1e0wdTbj6TfpLqfOfYjzqOX17L0pUmNGGfSIdr-n_0BE/edit?usp=drive_web
   </li>
   <li>
    https://docs.google.com/document/d/1akczbgY2f6M-y2FHY649C917KToSU8tj2Y1A7bCfq7k/edit?usp=drive_web
   </li>
   <li>
    https://docs.google.com/document/d/1gWr73U7uhIxzi8MOODNMafwDK7l-BDg3HsCEyc4xaGE/edit?usp=drive_web
   </li>
  </ul>
  <h2 id="in-r">
   <a>
    1.2. ... in R
   </a>
  </h2>
  <div class="sourceCode">
   <pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rowSums</span>(my_mat)
<span class="kw">colSums</span>(my_mat)
<span class="kw">mean</span>(my_vec, <span class="dt">trim =</span> <span class="dv">0</span>, <span class="dt">na.rm =</span> <span class="ot">FALSE</span>, ...)  
<span class="co"># trim is used to drop some observations from both end of the sorted vector; </span>
<span class="co"># When trim = 0.3, 3 values from each end will be dropped from the calculations to find mean. </span>
<span class="co"># na.rm is used to remove the missing values from the input vector. </span>
<span class="co"># If there are missing values, then the mean function returns NA; </span>
<span class="co"># To drop the missing values from the calculation use na.rm = TRUE.</span>

<span class="co"># elementwise sum</span>
my_vec1 +<span class="st"> </span>my_vec2  
<span class="co"># sum of vector elements: </span>
<span class="kw">sum</span>(my_vector)

<span class="kw">mean</span>(my_vector)
<span class="kw">seq</span>(a,b,<span class="dt">length.out=</span>n)
<span class="kw">crossprod</span>(x_vec,y_vec)

<span class="kw">ceiling</span>(x)
<span class="kw">floor</span>(x)
<span class="kw">trunc</span>(x, ...)
<span class="kw">round</span>(x, <span class="dt">digits =</span> <span class="dv">0</span>)
<span class="kw">signif</span>(x, <span class="dt">digits =</span> <span class="dv">6</span>)

<span class="co"># absolute value</span>
<span class="kw">abs</span>()
<span class="co"># absolute difference</span>
<span class="kw">abs</span>(x1-x2) 

<span class="kw">mean</span>()
<span class="kw">nchar</span>(my_vec)  
<span class="co"># counts number of characters in a vector of characters (strings)</span>

<span class="kw">max</span>(my_data, <span class="dt">na.rm =</span> <span class="ot">FALSE</span>, ...)
<span class="kw">min</span>(my_data)
<span class="kw">summary</span>()
<span class="kw">var</span>()
<span class="kw">median</span>()

<span class="co"># confidence intervals: </span>
<span class="kw">inference</span>(my_dav, <span class="dt">type=</span><span class="st">"ci"</span>, <span class="dt">method=</span><span class="st">"simulation"</span>, <span class="dt">conflevel=</span><span class="fl">0.9</span>, <span class="dt">est=</span><span class="st">"mean"</span>, <span class="dt">boot_method=</span><span class="st">"perc"</span>)
<span class="co"># method=simulation, theoretical</span>
<span class="co"># boot_method=perc, se</span>
<span class="co"># est=mean, median, proportion</span>

<span class="co"># hypothesis testing: </span>
<span class="kw">inference</span>(<span class="dt">y =</span> nc$weight, <span class="dt">x =</span> nc$habit, <span class="dt">est =</span> <span class="st">"mean"</span>, <span class="dt">type =</span> <span class="st">"ht"</span>, <span class="dt">null =</span> <span class="dv">0</span>, <span class="dt">alternative =</span> <span class="st">"twosided"</span>, <span class="dt">method =</span> <span class="st">"theoretical"</span>)
<span class="co"># alternative=”greater”</span>
<span class="kw">inference</span>(us12$response, <span class="dt">est =</span> <span class="st">"proportion"</span>,  <span class="dt">type =</span> <span class="st">"ci"</span>, <span class="dt">method =</span> <span class="st">"theoretical"</span>,  <span class="dt">success =</span> <span class="st">"atheist"</span>)

<span class="co"># compare: </span>
<span class="kw">by</span>(numerical_dataset, categorical_dataset, mean/length/...)
<span class="kw">cor</span>(var1, var2)

<span class="co"># http://www.rdocumentation.org/packages/stats/versions/3.3.1/topics/sd?</span>

<span class="co"># probability (in/dependent events and simulating event sequences)</span>
<span class="co"># simulate: </span>
possible_values &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"heads"</span>, <span class="st">"tails"</span>)
<span class="kw">sample</span>(possible_values, <span class="dt">size=</span>, <span class="dt">replace=</span>, <span class="dt">prob=</span><span class="kw">c</span>())

<span class="co"># generate sample distribution: The sampling distribution is calculated by resampling from the population,</span>
<span class="co"># the bootstrap distribution is calculated by resampling from the sample; </span>
<span class="co"># To construct the 95% bootstrap confidence interval using the percentile method, </span>
<span class="co"># we estimate the values of the 5th and 95th percentiles of the bootstrap distribution.</span>
<span class="co"># Set up an empty vector of 5000 NAs to store sample means:</span>
sample_means50 &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="dv">5000</span>)

<span class="co"># Take 5000 samples of size 50 of 'area' and store all of them in 'sample_means50'.</span>
for (i in <span class="dv">1</span>:<span class="dv">5000</span>) {
 samp &lt;-<span class="st"> </span><span class="kw">sample</span>(area, <span class="dv">50</span>)
 sample_means50[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(samp)
}

<span class="co"># View the result. If you want, you can increase the bin width to show more detail by changing the 'breaks' argument.</span>
<span class="kw">hist</span>(sample_means50, <span class="dt">breaks =</span> <span class="dv">13</span>)

<span class="co"># calculate 95 pct conf interval:</span>
se &lt;-<span class="st"> </span><span class="kw">sd</span>(samp)/<span class="kw">sqrt</span>(<span class="dv">60</span>)
lower &lt;-<span class="st"> </span>sample_mean -<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>se
upper &lt;-<span class="st"> </span>sample_mean +<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>se
<span class="kw">c</span>(lower, upper)

<span class="co"># inference:</span>
<span class="co"># ANOVA test: https://statistics.laerd.com/statistical-guides/one-way-anova-statistical-guide.php, https://explorable.com/anova </span>

<span class="co"># multivariate regression, looking for the best model:</span>
<span class="co"># start with a full model: </span>
m_full &lt;-<span class="st"> </span><span class="kw">lm</span>(score ~<span class="st"> </span>rank +<span class="st"> </span>ethnicity +<span class="st"> </span>gender +<span class="st"> </span>language +<span class="st"> </span>age +<span class="st"> </span>cls_perc_eval +<span class="st"> </span>cls_students +<span class="st"> </span>cls_level +<span class="st"> </span>cls_profs +<span class="st"> </span>cls_credits +<span class="st"> </span>bty_avg, <span class="dt">data =</span> evals)
<span class="co"># check p values for each coefficient; drop one with highest p-value</span>
<span class="co"># drop the variable that, when dropped, leads to the best improvement in R2</span></code></pre>
  </div>
  <h2 id="in-python">
   <a>
    1.3. ... in Python
   </a>
  </h2>
  <p>
   numpy has an arrays datatype, essential for analytic operations. arrays are like lists, but you can perform elementwise calculations on them and, unlike lists, they are cannot contain multiple types within one array; they are type coercive.
  </p>
  <div class="sourceCode">
   <pre class="sourceCode python"><code class="sourceCode python"><span class="co"># create an array: </span>
array_name <span class="op">=</span> np.array(list_name)
np.array([list1],[list2])
np.column_stack((list1, list2))

<span class="co"># subsetting arrays is the same as for lists, plus:</span>
<span class="co"># conditional selection: </span>
bmi[bmi<span class="op">&gt;</span><span class="dv">23</span>]<span class="op">;</span> 
<span class="co"># access specific cell: </span>
array_name[row,col]

<span class="co"># check dimensions: </span>
a_name.shape, a_name.size
<span class="co"># calculate average: </span>
np.mean(list_name)
<span class="co"># calculate median: </span>
np.median(list_name)
<span class="co"># calculate st dev: </span>
np.std(list_name)
<span class="co"># check correlation: </span>
np.corrcoef(list1,list2)
<span class="co"># add: </span>
np.<span class="bu">sum</span>(list_name)
<span class="co"># simulate random data: </span>
np.<span class="bu">round</span>(np.random.normal(mean, stdev, <span class="co">#obs), 2)</span>

<span class="im">import</span> random
random.choice(strname)
random.randint(a_inclusive,b_inclusive)</code></pre>
  </div>
  <h2 id="sources">
   <a>
    1.4. Sources
   </a>
  </h2>
  <h3 id="references">
   <a>
    1.4.1. References
   </a>
  </h3>
  <ul>
   <li>
    <a href="http://www.dummies.com/how-to/content/statistics-for-dummies-cheat-sheet.html">
     1,
    </a>
    <a href="http://web.mit.edu/~csvoss/Public/usabo/stats_handout.pdf">
     2,
    </a>
    <a href="https://drive.google.com/open?id=0B6XYyy1UbJ3XR2w5Snc2ck1BVFE">
     3
    </a>
   </li>
   <li>
    <a href="https://www.causeweb.org/cause/resources">
     CAUSEWeb statistics database
    </a>
   </li>
   <li>
    <a href="http://andrewgelman.com/2009/05/24/handy_statistic/">
     Andrew Gelman's round up of his stats writing
    </a>
   </li>
  </ul>
  <h3 id="read">
   <a>
    1.4.2. Read
   </a>
  </h3>
  <ul>
   <li>
    <em>
     The Seven Pillars of Statistical Wisdom
    </em>
   </li>
   <li>
    <em>
     Cartoon Guide to Statistics
    </em>
   </li>
   <li>
    <em>
     The Drunkard’s Walk
    </em>
   </li>
   <li>
    <a href="https://www.khanacademy.org/mission/probability">
     Khan Academy - Probability &amp; Statistics
    </a>
   </li>
   <li>
    <a href="https://drive.google.com/open?id=1lNnLujwLNRt_dDBdl0S31bDPtw0-da9PXiImPjBusdE">
     What is a P-Value Anyway? 34 Stories
    </a>
   </li>
   <li>
    <a href="http://courses.ncssm.edu/math/Talks/PDFS/normal.pdf">
     The normal distribution: A derivation from basic principles
    </a>
   </li>
   <li>
    <a href="http://math.stackexchange.com/questions/940189/intuition-behind-normal-distribution-forumula">
     Intuition behind normal distribution
    </a>
   </li>
   <li>
    <a href="http://stats.stackexchange.com/questions/85387/intuition-behind-standard-deviation">
     Intuition behind standard deviation
    </a>
   </li>
   <li>
    <a href="http://stats.stackexchange.com/questions/81986/mean-absolute-deviation-vs-standard-deviation">
     Mean absolute deviation versus standard deviation
    </a>
   </li>
   <li>
    <a href="http://www.leeds.ac.uk/educol/documents/00003759.htm">
     The advantages of the mean deviation
    </a>
   </li>
   <li>
    <a href="https://learnandteachstatistics.wordpress.com/2013/06/24/difficult-concepts/">
     Difficult concepts in statistics
    </a>
   </li>
  </ul>
  <h3 id="unread">
   <a>
    1.4.3. Unread
   </a>
  </h3>
  <ul>
   <li>
    <a href="http://nbviewer.jupyter.org/url/norvig.com/ipython/Probability.ipynb">
     A concrete introduction to probability using Python
    </a>
   </li>
   <li>
    <a href="http://xcelab.net/rm/statistical-rethinking/">
     Statistical Rethinking: A Bayesian Course in R
    </a>
   </li>
   <li>
    <a href="https://www.edx.org/course/mitx/mitx-6-041x-introduction-probability-1296#.U3yb762SzIo">
     EdX - Intro. Probability
    </a>
   </li>
   <li>
    <a href="http://bayes.wustl.edu/etj/prob/book.pdf">
     Probability theory: The logic of science
    </a>
   </li>
   <li>
    <a href="http://www.jerrydallal.com/LHSP/LHSP.HTM">
     The Little Handbook of Statistical Practice
    </a>
   </li>
   <li>
    <a href="https://www.openintro.org/stat/index.php">
     OpenIntro Statistics
    </a>
   </li>
   <li>
    <a href="https://en.wikipedia.org/wiki/Notation_in_probability_and_statistics">
     Notation in probability in statistics
    </a>
   </li>
   <li>
    Visualizations &amp; interactives:
    <a href="http://highered.mheducation.com/sites/0070000237/student_view0/visual_statistics.html">
     1,
    </a>
    <a href="http://statpages.info/">
     2,
    </a>
    <a href="http://www.math.uah.edu/stat/apps/index.html">
     3,
    </a>
    <a href="http://onlinestatbook.com/stat_sim/index.html">
     4
    </a>
   </li>
   <li>
    <a href="http://www.jerrydallal.com/LHSP/bmj.htm">
     British Medical Journal: Statistics notes
    </a>
   </li>
   <li>
    <a href="http://www.datasciencecentral.com/profiles/blogs/10-modern-statistical-concepts-discovered-by-data-scientists">
     10 Modern Statistical Concepts Discovered by Data Scientists
    </a>
   </li>
  </ul>
  <h1 id="linear-algebra">
   <a>
    2. Linear Algebra
   </a>
  </h1>
  <ul>
   <li>
    <a href="http://joshua.smcvt.edu/linearalgebra/">
     <i>
      Linear algebra
     </i>
    </a>
   </li>
   <li>
    <a href="http://linear.ups.edu/">
     A first course in linear algebra
    </a>
   </li>
   <li>
    <a href="https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/">
     PCA 4 Dummies: Eigenvectors/values &amp; dimension reduction
    </a>
   </li>
  </ul>
  <h1 id="relationships-trends">
   <a>
    3. Relationships &amp; Trends
   </a>
  </h1>
  <ul>
   <li>
    <a href="http://www.physics.csbsju.edu/stats/contingency_NROW_NCOLUMN_form.html">
     Contingency table calculator
    </a>
   </li>
   <li>
    <a href="https://drive.google.com/open?id=1-3rUQMEKFaPoNtDHLfZGIqZkgpqvr9b_2Tx7HQQzrTg">
     Understanding Multivariate Research
    </a>
   </li>
   <li>
    <a href="http://stats.stackexchange.com/questions/99094/intuition-on-the-definition-of-the-covariance">
     Intuition on the definition of covariance
    </a>
   </li>
   <li>
    <a href="http://stats.stackexchange.com/questions/29713/what-is-covariance-in-plain-language">
     What is covariance in plain language
    </a>
   </li>
   <li>
    <a href="http://stats.stackexchange.com/questions/18058/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean">
     How would you explain covariance
    </a>
   </li>
   <li>
    <a href="http://www.win-vector.com/blog/2011/11/correlation-and-r-squared/">
     Correlation &amp; R
     <sup style="background-color:transparent">
      2
     </sup>
    </a>
   </li>
   <li>
    <a href="http://prometheuswiki.publish.csiro.au/tiki-index.php?page=r+and+R2">
     r and R
     <sup>
      2
     </sup>
    </a>
   </li>
   <li>
    <a href="http://stats.stackexchange.com/questions/13314/is-r2-useful-or-dangerous/">
     Is R
     <sup>
      2
     </sup>
     useful or dangerous?
    </a>
   </li>
   <li>
    <a href="http://stats.stackexchange.com/questions/13266/simple-linear-regression-output-interpretation/13269#13269">
     Simple linear regression output interpretation
    </a>
   </li>
   <li>
    <a href="https://www.khanacademy.org/math/probability/regression">
     Khan Academy: Regression
    </a>
   </li>
   <li>
    <a href="http://faculty.chicagobooth.edu/midwest.econometrics/papers/megspanos.pdf">
     Statistical Model Specification and Validation
    </a>
   </li>
   <li>
    <a href="http://ocw.uc3m.es/economia/econometrics/lecture-notes-1/Topic5_logo.pdf">
     Specification Errors
    </a>
   </li>
   <li>
    <a href="http://www.nyu.edu/classes/nagler/quant2/notes/model_specification_oh.pdf">
     Notes on model specification
    </a>
   </li>
   <li>
    <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2744485/">
     Overadjustment bias and unnecessary adjustment
    </a>
   </li>
   <li>
    <a href="https://drive.google.com/open?id=1rbtRgb84K1WhncEmz4rrgU11YHKtCYPpiaGofKrEWbQ">
     The Chicago Guide to Writing About Multivariate Analysis
    </a>
   </li>
   <li>
    <a href="http://www3.wabash.edu/econometrics/EconometricsBook/index.htm">
     Introductory Econometrics
    </a>
   </li>
   <li>
    <a href="https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/">
     7 types of regression you should know
    </a>
   </li>
   <li>
    <a href="http://www.datasciencecentral.com/profiles/blogs/10-types-of-regressions-which-one-to-use">
     10 types of regression: which to use?
    </a>
   </li>
   <li>
    <a href="https://www.analyticsvidhya.com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/">
     Going Deeper into Regression Analysis with Assumptions
    </a>
   </li>
   <li>
    <a href="https://www.analyticsvidhya.com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/">
     Plots &amp; Solutions
    </a>
   </li>
   <li>
    <a href="http://www.datasciencecentral.com/profiles/blogs/tutorial-how-to-detect-spurious-correlations-and-how-to-find-the-">
     How to detect spurious correlations, and how to find the real ones
    </a>
   </li>
   <li>
    <a href="http://www.datasciencecentral.com/profiles/blogs/the-best-kept-secret-about-linear-and-logistic-regression">
     The best kept secret about linear and logistic regression
    </a>
   </li>
   <li>
    <a href="http://www.datasciencecentral.com/profiles/blogs/jackknife-logistic-and-linear-regression">
     Jackknife logistic and linear regression for clustering and predictions
    </a>
   </li>
   <li>
    <a href="https://onlinecourses.science.psu.edu/stat501/node/2">
     STAT 501: Regression Methods @ Penn State
    </a>
   </li>
   <li>
    Regression tutorias:
    <a href="http://blog.minitab.com/blog/adventures-in-statistics/regression-analysis-tutorial-and-examples">
     1,
    </a>
    <a href="http://denninginstitute.com/modules/dau/stat/regression/linregsn/linregsn_frm.html">
     2,
    </a>
    <a href="http://illuminations.nctm.org/Search.aspx?view=search&amp;type=ac&amp;kw=regression">
     3,
    </a>
    <a href="https://www.causeweb.org/cause/archive/repository/StarLibrary/activities/miller2001/">
     4a,
    </a>
    <a href="https://www.causeweb.org/cause/archive/repository/StarLibrary/activities/miller2001/Reg_Residuals.htm">
     4b,
    </a>
    <a href="http://statpages.info/#Regression">
     5
    </a>
   </li>
   <li>
    <a href="https://economictheoryblog.com/2016/02/20/rebuild-ols-estimator-manually-in-r/">
     Rebuild OLS estimators in R
    </a>
   </li>
   <li>
    <a href="http://blog.yhat.com/posts/r-lm-summary.html">
     Fitting and interpreting linear models in R
    </a>
   </li>
   <li>
    <a href="http://www.montana.edu/screel/Webpages/conservation%20biology/Interpreting%20Regression%20Coefficients.html#/">
     Understanding lm() output
    </a>
   </li>
   <li>
    <a href="http://www.r-tutor.com/elementary-statistics/simple-linear-regression/residual-plot">
     Residuals plot
    </a>
   </li>
   <li>
    <a href="https://rstudio-pubs-static.s3.amazonaws.com/119859_a290e183ff2f46b2858db66c3bc9ed3a.html">
     Guide to interpreting R regression output
    </a>
   </li>
   <li>
    <a href="http://www.win-vector.com/blog/2013/02/dont-use-correlation-to-track-prediction-performance/">
     Don’t use correlation to track prediction performance
    </a>
   </li>
   <li>
    <a href="http://www.statsmakemecry.com/smmctheblog/stats-soup-anova-ancova-manova-mancova">
     Statistical Soup: ANOVA, ANCOVA, MANOVA, &amp; MANCOVA
    </a>
   </li>
   <li>
    <a href="http://varianceexplained.org/r/beta_binomial_baseball/">
     Understanding beta binomial regression
    </a>
   </li>
   <li>
    <a href="http://people.stern.nyu.edu/wgreene/Econometrics/PanelDataNotes.htm">
     Econometric analysis of panel data, class notes
    </a>
   </li>
   <li>
    <a href="http://courses.umass.edu/econ753/">
     Applied econometrics syllabus
    </a>
   </li>
  </ul>
  <h1 id="hypothesis-ab-testing">
   <a>
    4. Hypothesis &amp; A/B Testing
   </a>
  </h1>
  <h2 id="references-1">
   <a>
    4.1. References
   </a>
  </h2>
  <ul>
   <li>
    Choosing the right test:
    <a href="http://www.graphpad.com/support/faqid/1790/">
     1,
    </a>
    <a href="http://www.ats.ucla.edu/stat/mult_pkg/whatstat/default.htm">
     2
    </a>
   </li>
  </ul>
  <h2 id="read-1">
   <a>
    4.2. Read
   </a>
  </h2>
  <ul>
   <li>
    <a href="https://www.khanacademy.org/math/probability/statistics-inferential">
     Khan Academy - Inferential Statistics
    </a>
   </li>
   <li>
    <a href="http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html">
     There is only one test
    </a>
   </li>
   <li>
    <a href="http://allendowney.stfi.re/2016/06/there-is-still-only-one-test.html?sf=gezyvye">
     There is still only one test
    </a>
   </li>
   <li>
    <a href="https://learnandteachstatistics.wordpress.com/2015/11/09/understanding-statistical-inference/">
     Understanding statistical inference
    </a>
   </li>
   <li>
    <a href="http://allendowney.blogspot.com/2015/03/statistical-inference-is-only-mostly.html">
     Statistical inference is only mostly wrong
    </a>
   </li>
   <li>
    <a href="https://www.painscience.com/articles/statistical-significance.php">
     Statistical significance abuse
    </a>
   </li>
   <li>
    <a href="https://www.theguardian.com/commentisfree/2011/sep/09/bad-science-research-error">
     Ignoring the ‘difference in differences’
    </a>
   </li>
   <li>
    <a href="http://allendowney.blogspot.com/2015/05/hypothesis-testing-is-only-mostly.html">
     Hypothesis testing is only mostly useless
    </a>
   </li>
   <li>
    <a href="http://www.perfendo.org/docs/BayesProbability/twelvePvaluemisconceptions.pdf">
     Twelve p value misconceptions
    </a>
   </li>
   <li>
    <a href="http://blogs.discovermagazine.com/neuroskeptic/2015/05/18/p-hacking-a-talk-and-further-thoughts/#.V18pwRMrLC2">
     p-hacking
    </a>
   </li>
   <li>
    <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf">
     The garden of forking paths
    </a>
   </li>
   <li>
    <a href="http://www.acrwebsite.org/volumes/v41/acr_v41_15833.pdf">
     Life after p-hacking
    </a>
   </li>
   <li>
    <a href="https://www.reddit.com/r/statistics/comments/2xg0cs/the_correct_interpretation_of_the_confidence/">
     The correct interpretation of the confidence interval
    </a>
   </li>
   <li>
    <a href="https://www.quora.com/What-is-the-most-intuitive-explanation-for-the-chi-square-test">
     Intuition for Chi-squared test
    </a>
   </li>
   <li>
    <a href="http://bblais.blogspot.com/2010/09/why-pseudoscientists-like-chi-square.html">
     Why pseudoscientists like chi-square
    </a>
   </li>
   <li>
    <a href="http://bblais.blogspot.com/2010/08/orthodox-statistics-conducive-to-pseudo.html">
     Chi-square versus psi
    </a>
   </li>
   <li>
    <a href="http://www.ling.upenn.edu/~clight/chisquared.htm">
     What is Chi-squared not for?
    </a>
   </li>
   <li>
    <a href="http://stats.stackexchange.com/questions/16921/how-to-understand-degrees-of-freedom/17148#17148">
     How to understand degrees of freedom
    </a>
   </li>
   <li>
    DOF:
    <a href="http://www.statsdirect.com/help/basics/degrees_of_freedom.htm">
     1,
    </a>
    <a href="http://www.jerrydallal.com/LHSP/dof.htm">
     2
    </a>
   </li>
   <li>
    <a href="http://web.bryant.edu/~bblais/deduction-induction-and-abduction-oh-my.html">
     Deduction, induction, and abduction
    </a>
   </li>
   <li>
    <a href="https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego">
     Bayes’ theorem with Legos
    </a>
   </li>
   <li>
    <a href="https://www.countbayesie.com/blog/2016/1/22/why-you-should-believe-your-friends-claims-about-food-allergies">
     Believe your friends’ allergies
    </a>
   </li>
   <li>
    <a href="https://www.countbayesie.com/blog/2015/2/18/hans-solo-and-bayesian-priors">
     Hans Solo and Bayesian priors
    </a>
   </li>
   <li>
    <a href="https://www.countbayesie.com/blog/2016/3/16/bayesian-reasoning-in-the-twilight-zone">
     Bayesian reasoning in the Twilight Zone
    </a>
   </li>
   <li>
    <a href="https://www.countbayesie.com/blog/2015/2/27/building-a-bayesian-voight-kampff-test">
     Bayes’ factor
    </a>
   </li>
  </ul>
  <h2>
   <a name="4.3.-unread">
    4.3. Unread
   </a>
  </h2>
  <ul>
   <li>
    <a href="http://varianceexplained.org/statistics/beta_distribution_and_baseball/">
     Understanding the beta distribution
    </a>
   </li>
   <li>
    <a href="https://www.countbayesie.com/blog/2015/4/4/parameter-estimation-the-pdf-cdf-and-quantile-function">
     Parameter estimation
    </a>
   </li>
   <li>
    <a href="https://www.countbayesie.com/blog/2015/4/4/parameter-estimation-adding-bayesian-priors">
     Bayesian priors for parameter estimation
    </a>
   </li>
   <li>
    <a href="http://varianceexplained.org/r/empirical_bayes_baseball/">
     Understanding empirical Bayes estimation
    </a>
   </li>
   <li>
    <a href="http://bayes.wustl.edu/etj/articles/confidence.pdf">
     Confidence intervals vs. Bayesian intervals
    </a>
   </li>
   <li>
    <a href="http://varianceexplained.org/r/credible_intervals_baseball/">
     Understanding credible intervals
    </a>
   </li>
   <li>
    <a href="https://www.countbayesie.com/blog/2015/4/25/bayesian-ab-testing">
     Hypothesis testing that makes sense
    </a>
   </li>
   <li>
    <a href="https://www.springboard.com/blog/probability-bayes-theorem-data-science/">
     How Bayes’ theorem, probability, logic and data intersect
    </a>
   </li>
   <li>
    <a href="http://www.oreilly.com/pub/e/3707">
     Learning to love Bayesian statistics
    </a>
   </li>
   <li>
    <a href="http://www.datasciencecentral.com/profiles/blogs/the-death-of-the-statistical-test-of-hypothesis">
     The death of statistical tests of hypotheses
    </a>
   </li>
   <li>
    <a href="http://www.datasciencecentral.com/profiles/blogs/biased-vs-unbiased-debunking-statistical-myths">
     Biased vs unbiased: debunking statistical myths
    </a>
   </li>
   <li>
    <a href="http://stat.ethz.ch/~stahel/lognormal/bioscience.pdf">
     Lognormal distributions across the sciences: Key and clues
    </a>
   </li>
   <li>
    <a href="http://www.wired.com/2012/04/ff_abtesting/">
     <font size="2">
      Wired - AB testing
     </font>
    </a>
   </li>
   <li>
    <a href="https://www.udacity.com/courses/ab-testing--ud257">
     Udacity - AB testing
    </a>
   </li>
   <li>
    <a href="http://varianceexplained.org/r/bayesian_ab_baseball/">
     Understanding Bayesian A/B testing
    </a>
   </li>
   <li>
    <a href="http://datacolada.org/41">
     Falsely reassuring: analyses of ALL p values
    </a>
   </li>
  </ul>
 </body>
</html>
