<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="text/css" http-equiv="Content-Style-Type"/>
  <meta content="pandoc" name="generator"/>
  <title>
   jtck.github.io | text analytics
  </title>
  <link href="../assets/styles/main.css" rel="stylesheet" type="text/css"/>
  <style type="text/css">
   table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
  <link href="../assets/styles/refs.css" rel="stylesheet" type="text/css"/>
 </head>
 <body>
  <p class="path">
   <a href="../pkb.html">
    pkb contents
   </a>
   &gt; text analytics | just under 1374 words | updated 12/28/2017
  </p>
  <div class="TOC">
   <ul>
    <li>
     1.
     <a href="#what-is-text-analytics">
      What is text analytics?
     </a>
     <ul>
      <li>
       1.1.
       <a href="#what-is-text-mining">
        What is text mining?
       </a>
      </li>
      <li>
       1.2.
       <a href="#business-applications-of-text-analytics">
        Business applications of text analytics
       </a>
       <ul>
        <li>
         1.2.1.
         <a href="#applications-by-industry">
          Applications by industry
         </a>
         <ul>
          <li>
           1.2.1.1.
           <a href="#information-management">
            Information management
           </a>
          </li>
          <li>
           1.2.1.2.
           <a href="#marketing">
            Marketing
           </a>
          </li>
          <li>
           1.2.1.3.
           <a href="#political-legal-military-security">
            Political, legal, military, security
           </a>
          </li>
          <li>
           1.2.1.4.
           <a href="#financial">
            Financial
           </a>
          </li>
          <li>
           1.2.1.5.
           <a href="#academic">
            Academic
           </a>
          </li>
          <li>
           1.2.1.6.
           <a href="#biomedical">
            Biomedical
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     2.
     <a href="#text-analytics-techniques">
      Text analytics techniques
     </a>
     <ul>
      <li>
       2.1.
       <a href="#text-mining">
        Text mining
       </a>
       <ul>
        <li>
         2.1.1.
         <a href="#web-mining">
          Web mining
         </a>
         <ul>
          <li>
           2.1.1.1.
           <a href="#search-engines-seo">
            Search engines &amp; SEO
           </a>
          </li>
          <li>
           2.1.1.2.
           <a href="#web-analytics">
            Web analytics
           </a>
          </li>
          <li>
           2.1.1.3.
           <a href="#social-analytics">
            Social analytics
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
      <li>
       2.2.
       <a href="#natural-language-processing-nlp">
        Natural language processing (NLP)
       </a>
       <ul>
        <li>
         2.2.1.
         <a href="#sentiment-analysis">
          Sentiment analysis
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     3.
     <a href="#doing-text-analytics">
      Doing text analytics
     </a>
     <ul>
      <li>
       3.1.
       <a href="#text-analytics-process">
        Text analytics process
       </a>
      </li>
      <li>
       3.2.
       <a href="#text-analytics-tools">
        Text analytics tools
       </a>
       <ul>
        <li>
         3.2.1.
         <a href="#ibm-watson">
          IBM Watson
         </a>
        </li>
        <li>
         3.2.2.
         <a href="#python">
          Python
         </a>
         <ul>
          <li>
           3.2.2.1.
           <a href="#string-manipulation">
            String manipulation
           </a>
          </li>
          <li>
           3.2.2.2.
           <a href="#regex">
            Regex
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     4.
     <a href="#sources">
      Sources
     </a>
     <ul>
      <li>
       4.1.
       <a href="#cited">
        Cited
       </a>
      </li>
      <li>
       4.2.
       <a href="#references">
        References
       </a>
      </li>
      <li>
       4.3.
       <a href="#read">
        Read
       </a>
      </li>
      <li>
       4.4.
       <a href="#unread">
        Unread
       </a>
      </li>
     </ul>
    </li>
   </ul>
  </div>
  <h1 id="what-is-text-analytics">
   <a>
    1. What is text analytics?
   </a>
  </h1>
  <p>
   Per Sharda et al. (2014, pp. 205-206),
   <strong>
    text analytics
   </strong>
   aims "to turn unstructured textual data into actionable information through the application of natural language processing (NLP) and analytics", the latter taking a 'bag of words' approach and the former taking a much more sophisticated approach rooted in linguistics.
  </p>
  <p>
   Text analytics includes the core activities of:
  </p>
  <ul>
   <li>
    <a href="https://jtkovacs.github.io/refs/information-architecture.html#what-is-information-retrieval">
     Information retrieval:
    </a>
    "searching and identifying relevant documents for a given set of key terms"; see
    <a href="https://jtkovacs.github.io/refs/search-engines.html">
     notes on search engines
    </a>
   </li>
   <li>
    <a href="https://jtkovacs.github.io/refs/text-analytics.html#text-mining">
     Text mining
    </a>
    AKA text data mining, AKA knowledge discovery in textual databases: "primarily focused on discovering new and useful relationships from the textual data sources"
   </li>
  </ul>
  <p>
   Text analytics is enabled by the foundational disciplines of:
  </p>
  <ul>
   <li>
    Statistics
   </li>
   <li>
    Computer Science
   </li>
   <li>
    Artificial Intelligence
   </li>
   <li>
    Machine Learning
   </li>
   <li>
    Natural Language Processing
   </li>
   <li>
    Linguistics
   </li>
   <li>
    Management Science
   </li>
  </ul>
  <h2 id="what-is-text-mining">
   <a>
    1.1. What is text mining?
   </a>
  </h2>
  <ul>
   <li>
    <strong>
     Information extraction:
    </strong>
    "identification of key phrases and relationships within text by looking for predefined objects and sequences by way of pattern matching"
   </li>
   <li>
    <strong>
     Web mining
    </strong>
    <ul>
     <li>
      Search engines (overlaps with "information retrieval")
     </li>
     <li>
      Web analytics
     </li>
     <li>
      Social media analytics
     </li>
    </ul>
   </li>
   <li>
    <a href="https://jtkovacs.github.io/refs/data-mining.html">
     Data mining
    </a>
   </li>
  </ul>
  <h2 id="business-applications-of-text-analytics">
   <a>
    1.2. Business applications of text analytics
   </a>
  </h2>
  <p>
   Per Sharda et al., some applications of text analytics (2014, pp. 206-207):
  </p>
  <ul>
   <li>
    <strong>
     "Topic tracking.
    </strong>
    Based on a user profile and documents that a user views, text mining can predict other documents of interest to the user.
   </li>
   <li>
    <strong>
     Categorization.
    </strong>
    Identifying the main themes of a document and them placing the document into a predefined set of categories based on those themes.
   </li>
   <li>
    <strong>
     Clustering.
    </strong>
    Grouping similar documents without having a predefined set of categories.
   </li>
   <li>
    <strong>
     Concept-linking.
    </strong>
    Connects related documents by identifying their shared concepts and, by doing so, helps users find information that they perhaps would not have found using traditional search methods."
   </li>
  </ul>
  <p>
   ... and some applications specifically enabled by NLP (p. 213):
  </p>
  <ul>
   <li>
    <strong>
     "Question-answering.
    </strong>
    ... producing a human language answer when given a human language question. ...
   </li>
   <li>
    <strong>
     Automatic summarization.
    </strong>
    The creation of a shortened version of a textual document by a computer program that contains the most important parts of the original document.
   </li>
   <li>
    <strong>
     Natural languge generation.
    </strong>
    Systems convert information from computer databases into readable human language.
   </li>
   <li>
    <strong>
     Natural language understanding.
    </strong>
    Systems convert samples of human language into more formal representations that are easier for computer programs to manipulate.
   </li>
   <li>
    <strong>
     Machine translation.
    </strong>
    Automatic translation of one human language to another.
   </li>
   <li>
    <strong>
     Foreign language reading.
    </strong>
    A computer program that assists a nonnative language speaker to read [or write, or speak] a foreign language ...
   </li>
   <li>
    <strong>
     Speech recognition.
    </strong>
    ... Given a sound clip of a person speaking, the system produces a text dictation.
   </li>
   <li>
    <strong>
     Text-to-speech.
    </strong>
    Also called
    <em>
     speech synthesis,
    </em>
    a computer program automatically converts normal language text into human speech.
   </li>
   <li>
    <strong>
     Text proofing.
    </strong>
    A computer program reads a proof copy of a text in order to detect and correct errors.
   </li>
   <li>
    <strong>
     Optical character recognition.
    </strong>
    The automatic translation of images of handwritten, typewritten, or printed text (usually captured by a scanner) into machine-editable textual documents."
   </li>
  </ul>
  <p>
   For a great example, see
   <a href="https://textio.com/">
    Textio: The Augmented Writing Platform.
   </a>
  </p>
  <h3 id="applications-by-industry">
   <a>
    1.2.1. Applications by industry
   </a>
  </h3>
  <h4 id="information-management">
   <a>
    1.2.1.1. Information management
   </a>
  </h4>
  <ul>
   <li>
    quarterly reports
   </li>
   <li>
    manage search engines
   </li>
   <li>
    manage websites
   </li>
   <li>
    email
    <ul>
     <li>
      classify
     </li>
     <li>
      filter junk
     </li>
     <li>
      prioritize
     </li>
     <li>
      generate automatic responses
     </li>
    </ul>
   </li>
  </ul>
  <h4 id="marketing">
   <a>
    1.2.1.2. Marketing
   </a>
  </h4>
  <ul>
   <li>
    <strong>
     Data sources:
    </strong>
    <ul>
     <li>
      call centers (notes and transcriptions)
     </li>
     <li>
      blogs
     </li>
     <li>
      user reviews
     </li>
     <li>
      discussion boards &amp; comment sections
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Information sought
    </strong>
    <ul>
     <li>
      customer perceptions in the market at-large
     </li>
     <li>
      CRM system-based insights about churn, perceptions, purchasing behavior
     </li>
    </ul>
   </li>
  </ul>
  <h4 id="political-legal-military-security">
   <a>
    1.2.1.3. Political, legal, military, security
   </a>
  </h4>
  <ul>
   <li>
    court orders
   </li>
   <li>
    patent files
   </li>
  </ul>
  <h4 id="financial">
   <a>
    1.2.1.4. Financial
   </a>
  </h4>
  <ul>
   <li>
    VOE, VOC, VOM (sentiment)
   </li>
  </ul>
  <h4 id="academic">
   <a>
    1.2.1.5. Academic
   </a>
  </h4>
  <ul>
   <li>
    citation analysis
   </li>
   <li>
    research articles
   </li>
  </ul>
  <h4 id="biomedical">
   <a>
    1.2.1.6. Biomedical
   </a>
  </h4>
  <ul>
   <li>
    medical records
   </li>
   <li>
    molecular interactions
   </li>
  </ul>
  <h1 id="text-analytics-techniques">
   <a>
    2. Text analytics techniques
   </a>
  </h1>
  <h2 id="text-mining">
   <a>
    2.1. Text mining
   </a>
  </h2>
  <ul>
   <li>
    Classification
   </li>
   <li>
    Association
   </li>
   <li>
    Clustering
   </li>
   <li>
    Trend analysis
   </li>
  </ul>
  <h3 id="web-mining">
   <a>
    2.1.1. Web mining
   </a>
  </h3>
  <p>
   Challenges
  </p>
  <h4 id="search-engines-seo">
   <a>
    2.1.1.1. Search engines &amp; SEO
   </a>
  </h4>
  <p>
   See
   <a href="https://jtkovacs.github.io/refs/search-engines.html">
    notes on search engines.
   </a>
  </p>
  <p>
   (mining content, structure)
  </p>
  <h4 id="web-analytics">
   <a>
    2.1.1.2. Web analytics
   </a>
  </h4>
  <p>
   (mining usage)
  </p>
  <ul>
   <li>
    metrics
   </li>
   <li>
    visitor profiles
   </li>
   <li>
    traffic
   </li>
   <li>
    usability
   </li>
   <li>
    conversion
   </li>
   <li>
    technologies
   </li>
  </ul>
  <h4 id="social-analytics">
   <a>
    2.1.1.3. Social analytics
   </a>
  </h4>
  <ul>
   <li>
    types of networks
   </li>
   <li>
    network metrics
   </li>
   <li>
    connections
   </li>
   <li>
    distributions
   </li>
   <li>
    segmentation
   </li>
   <li>
    social media analytics
   </li>
   <li>
    social media vs traditional media
   </li>
   <li>
    types of social media users
   </li>
   <li>
    measuring social media impact
   </li>
  </ul>
  <h2 id="natural-language-processing-nlp">
   <a>
    2.2. Natural language processing (NLP)
   </a>
  </h2>
  <p>
   vs. bag of words
  </p>
  <p>
   challenges
  </p>
  <h3 id="sentiment-analysis">
   <a>
    2.2.1. Sentiment analysis
   </a>
  </h3>
  <ul>
   <li>
    Process, pp. 234
   </li>
  </ul>
  <h1 id="doing-text-analytics">
   <a>
    3. Doing text analytics
   </a>
  </h1>
  <h2 id="text-analytics-process">
   <a>
    3.1. Text analytics process
   </a>
  </h2>
  <p>
   Per Sharda et al. (2014, p. 220):
  </p>
  <ol style="list-style-type: decimal">
   <li>
    Establish the corpus
   </li>
   <li>
    Create term-document matrix
   </li>
   <li>
    Analyze
   </li>
  </ol>
  <h2 id="text-analytics-tools">
   <a>
    3.2. Text analytics tools
   </a>
  </h2>
  <h3 id="ibm-watson">
   <a>
    3.2.1. IBM Watson
   </a>
  </h3>
  <p>
   IBM Watson's DeepQA is a "massively parallel, text mining-focused, probabilistic evidence-based computational architecture ... [using] more than 100 different techniques for analyzing natural language, identifying sources, finding and generating hypotheses, finding and scoring evidence, and merging and ranking hypotheses" (Sharda et al., 2014, pp. 203-204):
  </p>
  <p>
   <img src="illos/DeepQA.png" width="600"/>
  </p>
  <h3 id="python">
   <a>
    3.2.2. Python
   </a>
  </h3>
  <pre class="sourceCode Python"><code class="sourceCode python"><span class="co"># reverse order of elements:</span>
<span class="dt">list</span>.reverse(), my_string[::-<span class="dv">1</span>]
<span class="co"># selectively replace:</span>
str_name.replace(‘this’,’with this’)
<span class="co"># find index of known element:</span>
<span class="dt">list</span>.index(‘str name’)
<span class="co"># times element occurs:</span>
<span class="dt">list</span>.count(‘em_name’) makes <span class="dt">tuple</span> <span class="kw">with</span> (index,value): <span class="dt">enumerate</span>(my_list)</code></pre>
  <h4 id="string-manipulation">
   <a>
    3.2.2.1. String manipulation
   </a>
  </h4>
  <pre class="sourceCode Python"><code class="sourceCode python"><span class="co"># remove punctuation</span>
<span class="ch">import</span> string
line.translate(<span class="ot">None</span>, string.punctuation)

<span class="co"># modify case</span>
my_string.lower()
my_string.upper()
my_string.capitalize()
my_string.title()

<span class="co"># remove whitespace by default, or remove specified characters</span>
my_string.strip(<span class="st">'chars'</span>)
my_string.lstrip()
my_string.rstrip()</code></pre>
  <h4 id="regex">
   <a>
    3.2.2.2. Regex
   </a>
  </h4>
  <pre class="sourceCode Python"><code class="sourceCode python"><span class="co"># search for substrings within string or subset of string (i inclusive to j exclusive)</span>
str_index = my_string.find(x,i,j)
str_index = my_string.index(x,i,j)  <span class="co"># raises ValueError if not found</span>
<span class="dt">str</span>.endswith(x,i,j)
<span class="dt">str</span>.startswith(x,i,j)
my_string.count(x,i,j)</code></pre>
  <ul>
   <li>
    https://docs.python.org/3/library/re.html
   </li>
   <li>
    https://docs.python.org/3/howto/regex.html
   </li>
   <li>
    http://nbviewer.jupyter.org/github/ptwobrussell/Mining-the-Social-Web-2nd-Edition/tree/master/ipynb/
   </li>
  </ul>
  <pre class="sourceCode Python"><code class="sourceCode python"><span class="co"># match the beginning of a string:</span>
re.match(pattern, text, flags)
re.match(r’Jac’, data) <span class="co"># the r denotes a raw string</span>

<span class="co"># search anywhere in a string:</span>
<span class="co"># first match only:</span>
re.search(pattern, text, flags)
<span class="co"># all nonoverlapping:</span>
re.findall(pattern, text, flags)

<span class="co"># phone number, note escaped parentheses:</span>
re.search(r’\(\d\d\d\) \d\d\d-\d\d\d\d’, data)
<span class="co"># make parentheses, space, hyphen optional in phone number</span>
r’\)?\d{<span class="dv">3</span>})?\s?-?\d\{<span class="dv">3</span>}-\d{<span class="dv">4</span>}’</code></pre>
  <p>
   flags:
  </p>
  <ul>
   <li>
    re.IGNORECASE or re.I will ignore word case
   </li>
   <li>
    re.VERBOSE or re.X let regexp span lines &amp; contain (ignored) whitespace or comments
   </li>
   <li>
    re.MULTILINE or re.M to make a pattern regard lines in your text as the beginning or end of a string
   </li>
   <li>
    multiple flags: re.findall(pattern, data, flag|flag|flag)
   </li>
  </ul>
  <pre class="sourceCode Python"><code class="sourceCode python"><span class="co"># store regex for reuse:</span>
my_regex = re.<span class="dt">compile</span>(pattern, flags)
re.search(my_regex, data)
<span class="co"># OR</span>
my_regex.search(data)

<span class="co"># loop to obtain iterable of match objects:</span>
<span class="kw">for</span> match in my_regex.finditer(data):
    <span class="dt">print</span>(‘{first} {last} &lt;{email}&gt;’.<span class="dt">format</span>(**match.groupdict()))</code></pre>
  <ul>
   <li>
    \w = any Unicode word character, \W = anything not a Unicode word character
   </li>
   <li>
    \s = any whitespace, \S = anything not whitespace, = tab
   </li>
   <li>
    \d = any number 0-9, \D = any non-number
   </li>
   <li>
    \b = word boundaries, \B = not word boundaries
   </li>
  </ul>
  <p>
   counts, for when something occurs multiple times:
  </p>
  <ul>
   <li>
    {3} = occurs 3 times, {,3} = 0-3 times, {3,} = 3 or more times, {3-5} = 3-5 times
   </li>
   <li>
    \w? = 0-1 word characters, \w* = 0-infinite word characters, \w+ = 1-infinite word characters
   </li>
  </ul>
  <p>
   sets let us combine explicit characters and escape patterns into pieces that can be repeated multiple time; they also let us specify pieces that should be left out of any matches: [aple] finds apple and pale, [a-z] finds any lowercase letter, [A-Z] finds uppercase, [a-zA-Z] finds any case, [^2] finds anything not two, [0-9] finds any number, [.]+ finds any # of , .
  </p>
  <pre class="sourceCode Python"><code class="sourceCode python"><span class="co"># groups search for multiple conditions simultaneously; note that ^ marks the beginning of the string, and $ marks the end; unnamed groups returned as tuples, named groups as dicts:</span>
my_var = re.findall (r’’’
    ^(?P&lt;name&gt;[-\w ]+,\s[-\w ]+)\t   <span class="co"># search for lastname, firstname</span>
    (\)?\d{<span class="dv">3</span>})?\s?-?\d\{<span class="dv">3</span>}-\d{<span class="dv">4</span>})? <span class="co"># search for phone number, optional</span>
    (?&lt;email&gt;[-\w\d.+]+ @[-\w\d.]+)\t$  <span class="co"># search for emails</span>
    ‘’’, data, flags)

<span class="co"># groups addressing</span>
my_var.groups()
my_var.group_dict()
my_var.group(‘group_name’)
my_var.group(<span class="dv">1</span>)</code></pre>
  <h1 id="sources">
   <a>
    4. Sources
   </a>
  </h1>
  <h2 id="cited">
   <a>
    4.1. Cited
   </a>
  </h2>
  <p>
   Sharda, R., Delen, D., &amp; Turban, E. (2014).
   <em>
    Business intelligence: A managerial perspective on analytics
   </em>
   (3rd ed.). New York City, NY: Pearson.
  </p>
  <h2 id="references">
   <a>
    4.2. References
   </a>
  </h2>
  <ul>
   <li>
    <a href="http://billchambers.me/tutorials/2015/01/14/python-nlp-cheatsheet-nltk-scikit-learn.html">
     NLTK cheatsheet
    </a>
   </li>
   <li>
    <a href="http://corpus.byu.edu/coca/">
     Corpus of Contemporary American English
    </a>
   </li>
   <li>
    <a href="http://cw.routledge.com/textbooks/0415286239/default.asp">
     Corpus based language studies
    </a>
   </li>
   <li>
    <a href="https://personality-insights-livedemo.mybluemix.net/">
     IBM Watson demo - Infer personality from unstructured text
    </a>
   </li>
  </ul>
  <h2 id="read">
   <a>
    4.3. Read
   </a>
  </h2>
  <ul>
   <li>
    <a href="http://www.lynda.com/Regular-Expressions-tutorials/Using-Regular-Expressions/85870-2.html">
     Lynda - Using Regex
    </a>
   </li>
  </ul>
  <h2>
   <a name="4.4.-unread">
    4.4. Unread
   </a>
  </h2>
  <ul>
   <li>
    Regex:
    <a href="http://www.regular-expressions.info/">
     1
    </a>
    ,
    <a href="https://regexone.com/">
     2
    </a>
   </li>
   <li>
    <a href="https://www.codeschool.com/courses/breaking-the-ice-with-regular-expressions">
     CodeSchool - Regular Expressions
    </a>
   </li>
   <li>
    <a href="http://www.datasciencecentral.com/profiles/blogs/5-easy-steps-to-structure-highly-unstructured-big-data">
     4 steps to structure highly unstructured big data via automated indexation
    </a>
   </li>
   <li>
    <a href="https://www.coursera.org/learn/nlp">
     Coursera - Natural Language Processing
    </a>
   </li>
   <li>
    <a href="http://bigdatauniversity.com/courses/text-analytics-essentials/">
     Big Data U - Text Analytics
    </a>
   </li>
   <li>
    <a href="http://nlpers.blogspot.co.uk/2016/06/language-bias-and-black-sheep.html">
     Language bias &amp; black sheep
    </a>
   </li>
   <li>
    <a href="http://www.nltk.org/book/">
     Analyzing Text with NLTK
    </a>
   </li>
   <li>
    <a href="http://www.panix.com/~elflord/unix/grep.html">
     Donovan Rebbechi's grep tutorial
    </a>
   </li>
   <li>
    <a href="http://www.uccs.edu/~ahitchco/grep/">
     Drew's grep tutorial
    </a>
   </li>
  </ul>
 </body>
</html>
