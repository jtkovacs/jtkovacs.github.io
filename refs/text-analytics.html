<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="text/css" http-equiv="Content-Style-Type"/>
  <meta content="pandoc" name="generator"/>
  <title>
   jtck.github.io | text analytics
  </title>
  <link href="../assets/styles/main.css" rel="stylesheet" type="text/css"/>
  <style type="text/css">
   table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
  <link href="../assets/styles/refs.css" rel="stylesheet" type="text/css"/>
 </head>
 <body>
  <p class="path">
   <a href="../pkb.html">
    pkb contents
   </a>
   &gt; text analytics | just under 2046 words | updated 12/28/2017
  </p>
  <div class="TOC">
   <ul>
    <li>
     1.
     <a href="#what-is-text-analytics">
      What is text analytics?
     </a>
     <ul>
      <li>
       1.1.
       <a href="#business-applications-of-text-analytics">
        Business applications of text analytics
       </a>
       <ul>
        <li>
         1.1.1.
         <a href="#applications-by-technique">
          Applications by technique
         </a>
        </li>
        <li>
         1.1.2.
         <a href="#applications-by-industry">
          Applications by industry
         </a>
         <ul>
          <li>
           1.1.2.1.
           <a href="#deception-detection">
            Deception detection
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
      <li>
       1.2.
       <a href="#text-mining-process">
        Text mining process
       </a>
       <ul>
        <li>
         1.2.1.
         <a href="#establish-the-corpus">
          Establish the corpus
         </a>
        </li>
        <li>
         1.2.2.
         <a href="#create-term-by-document-matrix">
          Create term-by-document matrix
         </a>
        </li>
        <li>
         1.2.3.
         <a href="#analyze">
          Analyze
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     2.
     <a href="#text-analytics-techniques">
      Text analytics techniques
     </a>
     <ul>
      <li>
       2.1.
       <a href="#key-definitions">
        Key definitions
       </a>
      </li>
      <li>
       2.2.
       <a href="#text-mining">
        Text mining
       </a>
       <ul>
        <li>
         2.2.1.
         <a href="#web-mining">
          Web mining
         </a>
         <ul>
          <li>
           2.2.1.1.
           <a href="#search-engines-seo">
            Search engines &amp; SEO
           </a>
          </li>
          <li>
           2.2.1.2.
           <a href="#web-analytics">
            Web analytics
           </a>
          </li>
          <li>
           2.2.1.3.
           <a href="#social-analytics">
            Social analytics
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
      <li>
       2.3.
       <a href="#natural-language-processing">
        Natural language processing
       </a>
       <ul>
        <li>
         2.3.1.
         <a href="#sentiment-analysis">
          Sentiment analysis
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     3.
     <a href="#text-analytics-tools">
      Text analytics tools
     </a>
     <ul>
      <li>
       3.1.
       <a href="#ibm-watson">
        IBM Watson
       </a>
      </li>
      <li>
       3.2.
       <a href="#python">
        Python
       </a>
       <ul>
        <li>
         3.2.1.
         <a href="#string-manipulation">
          String manipulation
         </a>
        </li>
        <li>
         3.2.2.
         <a href="#regex">
          Regex
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     4.
     <a href="#sources">
      Sources
     </a>
     <ul>
      <li>
       4.1.
       <a href="#cited">
        Cited
       </a>
      </li>
      <li>
       4.2.
       <a href="#references">
        References
       </a>
      </li>
      <li>
       4.3.
       <a href="#read">
        Read
       </a>
      </li>
      <li>
       4.4.
       <a href="#unread">
        Unread
       </a>
      </li>
     </ul>
    </li>
   </ul>
  </div>
  <h1 id="what-is-text-analytics">
   <a>
    1. What is text analytics?
   </a>
  </h1>
  <p>
   Per Sharda et al. (2014, pp. 205-206),
   <strong>
    text analytics
   </strong>
   aims "to turn unstructured textual data into actionable information through the application of [techniques from] natural language processing (NLP) and analytics [i.e., [data mining]" ---](https://jtkovacs.github.io/refs/data-mining.html#what-is-data-mining) the latter taking a 'bag of words' approach and the former taking a much more sophisticated approach rooted in linguistics.
  </p>
  <p>
   Text analytics includes the core activities of:
  </p>
  <ul>
   <li>
    <strong>
     Information retrieval:
    </strong>
    "searching and identifying relevant documents for a given set of key terms"; see
    <a href="https://jtkovacs.github.io/refs/search-engines.html">
     notes on search engines
    </a>
    and
    <a href="https://jtkovacs.github.io/refs/information-architecture.html#what-is-information-retrieval">
     IA for information retrieval
    </a>
   </li>
   <li>
    <a href="https://jtkovacs.github.io/refs/text-analytics.html#text-mining">
     Text mining
    </a>
    AKA text data mining, AKA knowledge discovery in textual databases: "primarily focused on discovering new and useful relationships from the textual data sources"
    <ul>
     <li>
      <strong>
       Information extraction:
      </strong>
      "identification of key phrases and relationships within text by looking for predefined objects and sequences by way of pattern matching"
     </li>
     <li>
      <strong>
       Web mining
      </strong>
      <ul>
       <li>
        Search engines (overlaps with "information retrieval")
       </li>
       <li>
        Web analytics
       </li>
       <li>
        Social media analytics
       </li>
      </ul>
     </li>
     <li>
      <a href="https://jtkovacs.github.io/refs/data-mining.html">
       Data mining
      </a>
     </li>
    </ul>
   </li>
  </ul>
  <p>
   Text analytics is enabled by the foundational disciplines of:
  </p>
  <ul>
   <li>
    Statistics
   </li>
   <li>
    Computer Science
    <ul>
     <li>
      Artificial Intelligence
     </li>
     <li>
      Machine Learning
     </li>
    </ul>
   </li>
   <li>
    Linguistics
    <ul>
     <li>
      Natural Language Processing
     </li>
    </ul>
   </li>
   <li>
    Management Science
   </li>
  </ul>
  <h2 id="business-applications-of-text-analytics">
   <a>
    1.1. Business applications of text analytics
   </a>
  </h2>
  <h3 id="applications-by-technique">
   <a>
    1.1.1. Applications by technique
   </a>
  </h3>
  <p>
   Per Sharda et al., some applications of text analytics (2014, pp. 206-207):
  </p>
  <ul>
   <li>
    <strong>
     "Topic tracking.
    </strong>
    Based on a user profile and documents that a user views, text mining can predict other documents of interest to the user.
   </li>
   <li>
    <strong>
     Categorization.
    </strong>
    Identifying the main themes of a document and them placing the document into a predefined set of categories based on those themes.
   </li>
   <li>
    <strong>
     Clustering.
    </strong>
    Grouping similar documents without having a predefined set of categories.
   </li>
   <li>
    <strong>
     Concept-linking.
    </strong>
    Connects related documents by identifying their shared concepts and, by doing so, helps users find information that they perhaps would not have found using traditional search methods."
   </li>
  </ul>
  <p>
   ... and some applications specifically enabled by NLP (p. 213; for a great example, see
   <a href="https://textio.com/">
    Textio, The Augmented Writing Platform):
   </a>
  </p>
  <ul>
   <li>
    <strong>
     "Question-answering.
    </strong>
    ... producing a human language answer when given a human language question. ...
   </li>
   <li>
    <strong>
     Automatic summarization.
    </strong>
    The creation of a shortened version of a textual document by a computer program that contains the most important parts of the original document.
   </li>
   <li>
    <strong>
     Natural languge generation.
    </strong>
    Systems convert information from computer databases into readable human language.
   </li>
   <li>
    <strong>
     Natural language understanding.
    </strong>
    Systems convert samples of human language into more formal representations that are easier for computer programs to manipulate.
   </li>
   <li>
    <strong>
     Machine translation.
    </strong>
    Automatic translation of one human language to another.
   </li>
   <li>
    <strong>
     Foreign language reading.
    </strong>
    A computer program that assists a nonnative language speaker to read [or write, or speak] a foreign language ...
   </li>
   <li>
    <strong>
     Speech recognition.
    </strong>
    ... Given a sound clip of a person speaking, the system produces a text dictation.
   </li>
   <li>
    <strong>
     Text-to-speech.
    </strong>
    Also called
    <em>
     speech synthesis,
    </em>
    a computer program automatically converts normal language text into human speech.
   </li>
   <li>
    <strong>
     Text proofing.
    </strong>
    A computer program reads a proof copy of a text in order to detect and correct errors.
   </li>
   <li>
    <strong>
     Optical character recognition.
    </strong>
    The automatic translation of images of handwritten, typewritten, or printed text (usually captured by a scanner) into machine-editable textual documents."
   </li>
  </ul>
  <p>
   ... and some applications specifically enabled by sentiment analysis, part of NLP (p. 233):
  </p>
  <ul>
   <li>
    <strong>
     Financial system,
    </strong>
    trying to predict based on buzz
   </li>
   <li>
    Understanding the 'voices' of employees (VOE), customers (VOC) and the market (VOM)
   </li>
   <li>
    Politics &amp; surveillance
   </li>
  </ul>
  <h3 id="applications-by-industry">
   <a>
    1.1.2. Applications by industry
   </a>
  </h3>
  <p>
   Per Sharda et al. (2014, pp. 213-220):
  </p>
  <ul>
   <li>
    <strong>
     Information management
    </strong>
    <ul>
     <li>
      quarterly reports
     </li>
     <li>
      manage search engines
     </li>
     <li>
      manage websites
     </li>
     <li>
      email
      <ul>
       <li>
        classify
       </li>
       <li>
        filter junk
       </li>
       <li>
        prioritize
       </li>
       <li>
        generate automatic responses
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Marketing
    </strong>
    <ul>
     <li>
      <em>
       Data sources
      </em>
      <ul>
       <li>
        call centers (notes and transcriptions)
       </li>
       <li>
        blogs
       </li>
       <li>
        user reviews
       </li>
       <li>
        discussion boards &amp; comment sections
       </li>
      </ul>
     </li>
     <li>
      <em>
       Information sought
      </em>
      <ul>
       <li>
        customer perceptions in the market at-large
       </li>
       <li>
        CRM system-based insights about churn, perceptions, purchasing behavior
       </li>
       <li>
        improve customer service performance by providing granular feedback on writing (e.g. email to customers)
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Legal
    </strong>
    <ul>
     <li>
      court orders
     </li>
     <li>
      patent files
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Security
    </strong>
    <ul>
     <li>
      ECHELON, "assumed to be capable of identifying the content of telephone calls, faxes, emails, and other types of data, intercepting information sent via satellites, publics-switched telephone networks, and microwave links"
     </li>
     <li>
      FBI &amp; CIA joint database development
     </li>
     <li>
      <a href="#deception-detection">
       deception detection
      </a>
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Academic &amp; biomedical
    </strong>
    <ul>
     <li>
      citation analysis
     </li>
     <li>
      research articles
     </li>
     <li>
      medical records
     </li>
     <li>
      molecular interactions
     </li>
    </ul>
   </li>
  </ul>
  <h4 id="deception-detection">
   <a>
    1.1.2.1. Deception detection
   </a>
  </h4>
  <p>
   Per Sharda et al. (2014, p. 216):
  </p>
  <p>
   "Applying text mining to a large set of real-world criminal (person-of-interest) statements, Fuller et al. (2008) developed prediction models to differentiate deceptive statements from truthful ones. Using a rich set of cues extracted from the textual statements, the model predicted the holdout samples with 70 percent accuracy, which is believed to be a significant success considering that the cues are extracted only from textual statementss (no verbal or visual cues are present). Furthermore, compared to other deception-detection techniques, such as polygraph, this method is nonintrusive and widely applicable to not only textual data, but also (potentially) to transcriptions of voice recordings."
  </p>
  <table>
   <thead>
    <tr class="header">
     <th align="left">
      Construct
     </th>
     <th align="left">
      Example Cues
     </th>
    </tr>
   </thead>
   <tbody>
    <tr class="odd">
     <td align="left">
      Quantity
     </td>
     <td align="left">
      Verb count, noun-phrase count
     </td>
    </tr>
    <tr class="even">
     <td align="left">
      Complexity
     </td>
     <td align="left">
      Average number of clauses, average sentence length
     </td>
    </tr>
    <tr class="odd">
     <td align="left">
      Uncertainty
     </td>
     <td align="left">
      Modifiers, modal verbs
     </td>
    </tr>
    <tr class="even">
     <td align="left">
      Nonimmediacy
     </td>
     <td align="left">
      Passive voice, objectification
     </td>
    </tr>
    <tr class="odd">
     <td align="left">
      Expressivity
     </td>
     <td align="left">
      Emotiveness
     </td>
    </tr>
    <tr class="even">
     <td align="left">
      Diversity
     </td>
     <td align="left">
      Lexical diversity, redundancy
     </td>
    </tr>
    <tr class="odd">
     <td align="left">
      Informality
     </td>
     <td align="left">
      Typographical error ratio
     </td>
    </tr>
    <tr class="even">
     <td align="left">
      Specificity
     </td>
     <td align="left">
      Spatiotemporal information, perceptual information
     </td>
    </tr>
    <tr class="odd">
     <td align="left">
      Affect
     </td>
     <td align="left">
      Positive affect, negative affect
     </td>
    </tr>
   </tbody>
  </table>
  <h2 id="text-mining-process">
   <a>
    1.2. Text mining process
   </a>
  </h2>
  <p>
   Per Sharda et al. (2014, pp. 220-226), text mining can be undertaken through the three-step process elaborated below. Delen and Crossland (2008, cited in Sharda et al., 2014) place the black box of this process into the following context, which they represent graphically:
  </p>
  <ul>
   <li>
    <strong>
     Input
    </strong>
   </li>
   <li>
    structured data
   </li>
   <li>
    unstructured data
   </li>
   <li>
    <strong>
     Constraints
    </strong>
    <ul>
     <li>
      software/hardware limitations
     </li>
     <li>
      privacy issues
     </li>
     <li>
      linguistic limitations
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Mechanisms
    </strong>
    <ul>
     <li>
      domain expertise
     </li>
     <li>
      tools &amp; techniques
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Output
    </strong>
    context-specific knowledge
   </li>
  </ul>
  <h3 id="establish-the-corpus">
   <a>
    1.2.1. Establish the corpus
   </a>
  </h3>
  <h3 id="create-term-by-document-matrix">
   <a>
    1.2.2. Create term-by-document matrix
   </a>
  </h3>
  <h3 id="analyze">
   <a>
    1.2.3. Analyze
   </a>
  </h3>
  <h1 id="text-analytics-techniques">
   <a>
    2. Text analytics techniques
   </a>
  </h1>
  <h2 id="key-definitions">
   <a>
    2.1. Key definitions
   </a>
  </h2>
  <p>
   From Sharda et al. (2014, pp. 207-208), some broad concepts:
  </p>
  <ul>
   <li>
    <strong>
     Morphology
    </strong>
    "branch of the field of linguistics and a part of natural language processing that studies the internal structure of words (patterns of word formation within a language or across languages)"
   </li>
   <li>
    <strong>
     Corpus
    </strong>
    "large and structured set of texts ... prepared for the purpose of conducting knowledge discovery"
   </li>
   <li>
    <strong>
     Lexicon
    </strong>
   </li>
   <li>
    <strong>
     Terms
    </strong>
    and
    <strong>
     polysemy
    </strong>
    (elemental units; single word or multi-word phrase, see
    <a href="https://jtkovacs.github.io/refs/information-architecture.html#what-are-controlled-vocabularies">
     notes on controlled vocabularies)
    </a>
    and
    <strong>
     Concepts
    </strong>
    (combinations of terms)
   </li>
  </ul>
  <p>
   ... and narrow ones::
  </p>
  <ul>
   <li>
    <strong>
     Stemming
    </strong>
    "reducing inflected words to their stem (or base or root) form"
   </li>
   <li>
    <strong>
     Stop words
    </strong>
    "(or noise words) ... are filtered out prior to or after processing of natural language data ... there is no universally accepted list of stop words, [but] most natural language processing tools use a list that includes articles
    <em>
     (a, an, the, of, etc.),
    </em>
    auxiliary verbs
    <em>
     (is, are, was, were, etc.),
    </em>
    and context-specific words that are deemed not to have any differentiating value"
   </li>
   <li>
    <strong>
     Term-by-document-matrix
    </strong>
    AKA occurrence matrix "common representation schema of the frequency-based relationship between the terms and documents in a tabular format where terms are listed in rows, documents are listed in columns, and the frequency between the terms and documents is listed in cells as integer values"
    <ul>
     <li>
      <strong>
       Latent semantic indexing
      </strong>
      by single-value decomposition (SVD) "dimensionality reduction method to transform the term-by-document matrix to a manageable size by generating an intermediate representation of the frequencies using a matrix manipulation method similar to principal component analysis"
     </li>
    </ul>
   </li>
   <li>
    <strong>
     Token
    </strong>
    "a categorized block of text in a sentence ... this assignment of meaning to blocks of text is known as
    <strong>
     tokenizing"
    </strong>
    <ul>
     <li>
      <strong>
       Part-of-speech tagging
      </strong>
     </li>
    </ul>
   </li>
  </ul>
  <h2 id="text-mining">
   <a>
    2.2. Text mining
   </a>
  </h2>
  <ul>
   <li>
    Classification
   </li>
   <li>
    Association
   </li>
   <li>
    Clustering
   </li>
   <li>
    Trend analysis
   </li>
  </ul>
  <h3 id="web-mining">
   <a>
    2.2.1. Web mining
   </a>
  </h3>
  <p>
   Challenges with web mining, per Sharda et al. (2014, p. 239) --- the Web is:
  </p>
  <ul>
   <li>
    Big, growing, and constantly updated
   </li>
   <li>
    Complex, e.g. authoring style, content variation, lack of unified structure, not specific to a domain
   </li>
  </ul>
  <h4 id="search-engines-seo">
   <a>
    2.2.1.1. Search engines &amp; SEO
   </a>
  </h4>
  <p>
   See
   <a href="https://jtkovacs.github.io/refs/search-engines.html">
    notes on search engines.
   </a>
  </p>
  <p>
   (mining content, structure)
  </p>
  <h4 id="web-analytics">
   <a>
    2.2.1.2. Web analytics
   </a>
  </h4>
  <p>
   (mining usage)
  </p>
  <ul>
   <li>
    metrics
   </li>
   <li>
    visitor profiles
   </li>
   <li>
    traffic
   </li>
   <li>
    usability
   </li>
   <li>
    conversion
   </li>
   <li>
    technologies
   </li>
  </ul>
  <h4 id="social-analytics">
   <a>
    2.2.1.3. Social analytics
   </a>
  </h4>
  <ul>
   <li>
    types of networks
   </li>
   <li>
    network metrics
   </li>
   <li>
    connections
   </li>
   <li>
    distributions
   </li>
   <li>
    segmentation
   </li>
   <li>
    social media analytics
   </li>
   <li>
    social media vs traditional media
   </li>
   <li>
    types of social media users
   </li>
   <li>
    measuring social media impact
   </li>
  </ul>
  <h2 id="natural-language-processing">
   <a>
    2.3. Natural language processing
   </a>
  </h2>
  <p>
   vs. bag of words
  </p>
  <p>
   challenges
  </p>
  <h3 id="sentiment-analysis">
   <a>
    2.3.1. Sentiment analysis
   </a>
  </h3>
  <ul>
   <li>
    Process, pp. 234
   </li>
  </ul>
  <h1 id="text-analytics-tools">
   <a>
    3. Text analytics tools
   </a>
  </h1>
  <h2 id="ibm-watson">
   <a>
    3.1. IBM Watson
   </a>
  </h2>
  <p>
   IBM Watson's DeepQA is a "massively parallel, text mining-focused, probabilistic evidence-based computational architecture ... [using] more than 100 different techniques for analyzing natural language, identifying sources, finding and generating hypotheses, finding and scoring evidence, and merging and ranking hypotheses" (Sharda et al., 2014, pp. 203-204):
  </p>
  <p>
   <img src="illos/DeepQA.png" width="600"/>
  </p>
  <h2 id="python">
   <a>
    3.2. Python
   </a>
  </h2>
  <pre class="sourceCode Python"><code class="sourceCode python"><span class="co"># reverse order of elements:</span>
<span class="dt">list</span>.reverse(), my_string[::-<span class="dv">1</span>]
<span class="co"># selectively replace:</span>
str_name.replace(‘this’,’with this’)
<span class="co"># find index of known element:</span>
<span class="dt">list</span>.index(‘str name’)
<span class="co"># times element occurs:</span>
<span class="dt">list</span>.count(‘em_name’) makes <span class="dt">tuple</span> <span class="kw">with</span> (index,value): <span class="dt">enumerate</span>(my_list)</code></pre>
  <h3 id="string-manipulation">
   <a>
    3.2.1. String manipulation
   </a>
  </h3>
  <pre class="sourceCode Python"><code class="sourceCode python"><span class="co"># remove punctuation</span>
<span class="ch">import</span> string
line.translate(<span class="ot">None</span>, string.punctuation)

<span class="co"># modify case</span>
my_string.lower()
my_string.upper()
my_string.capitalize()
my_string.title()

<span class="co"># remove whitespace by default, or remove specified characters</span>
my_string.strip(<span class="st">'chars'</span>)
my_string.lstrip()
my_string.rstrip()</code></pre>
  <h3 id="regex">
   <a>
    3.2.2. Regex
   </a>
  </h3>
  <pre class="sourceCode Python"><code class="sourceCode python"><span class="co"># search for substrings within string or subset of string (i inclusive to j exclusive)</span>
str_index = my_string.find(x,i,j)
str_index = my_string.index(x,i,j)  <span class="co"># raises ValueError if not found</span>
<span class="dt">str</span>.endswith(x,i,j)
<span class="dt">str</span>.startswith(x,i,j)
my_string.count(x,i,j)</code></pre>
  <ul>
   <li>
    https://docs.python.org/3/library/re.html
   </li>
   <li>
    https://docs.python.org/3/howto/regex.html
   </li>
   <li>
    http://nbviewer.jupyter.org/github/ptwobrussell/Mining-the-Social-Web-2nd-Edition/tree/master/ipynb/
   </li>
  </ul>
  <pre class="sourceCode Python"><code class="sourceCode python"><span class="co"># match the beginning of a string:</span>
re.match(pattern, text, flags)
re.match(r’Jac’, data) <span class="co"># the r denotes a raw string</span>

<span class="co"># search anywhere in a string:</span>
<span class="co"># first match only:</span>
re.search(pattern, text, flags)
<span class="co"># all nonoverlapping:</span>
re.findall(pattern, text, flags)

<span class="co"># phone number, note escaped parentheses:</span>
re.search(r’\(\d\d\d\) \d\d\d-\d\d\d\d’, data)
<span class="co"># make parentheses, space, hyphen optional in phone number</span>
r’\)?\d{<span class="dv">3</span>})?\s?-?\d\{<span class="dv">3</span>}-\d{<span class="dv">4</span>}’</code></pre>
  <p>
   flags:
  </p>
  <ul>
   <li>
    re.IGNORECASE or re.I will ignore word case
   </li>
   <li>
    re.VERBOSE or re.X let regexp span lines &amp; contain (ignored) whitespace or comments
   </li>
   <li>
    re.MULTILINE or re.M to make a pattern regard lines in your text as the beginning or end of a string
   </li>
   <li>
    multiple flags: re.findall(pattern, data, flag|flag|flag)
   </li>
  </ul>
  <pre class="sourceCode Python"><code class="sourceCode python"><span class="co"># store regex for reuse:</span>
my_regex = re.<span class="dt">compile</span>(pattern, flags)
re.search(my_regex, data)
<span class="co"># OR</span>
my_regex.search(data)

<span class="co"># loop to obtain iterable of match objects:</span>
<span class="kw">for</span> match in my_regex.finditer(data):
    <span class="dt">print</span>(‘{first} {last} &lt;{email}&gt;’.<span class="dt">format</span>(**match.groupdict()))</code></pre>
  <ul>
   <li>
    \w = any Unicode word character, \W = anything not a Unicode word character
   </li>
   <li>
    \s = any whitespace, \S = anything not whitespace, = tab
   </li>
   <li>
    \d = any number 0-9, \D = any non-number
   </li>
   <li>
    \b = word boundaries, \B = not word boundaries
   </li>
  </ul>
  <p>
   counts, for when something occurs multiple times:
  </p>
  <ul>
   <li>
    {3} = occurs 3 times, {,3} = 0-3 times, {3,} = 3 or more times, {3-5} = 3-5 times
   </li>
   <li>
    \w? = 0-1 word characters, \w* = 0-infinite word characters, \w+ = 1-infinite word characters
   </li>
  </ul>
  <p>
   sets let us combine explicit characters and escape patterns into pieces that can be repeated multiple time; they also let us specify pieces that should be left out of any matches: [aple] finds apple and pale, [a-z] finds any lowercase letter, [A-Z] finds uppercase, [a-zA-Z] finds any case, [^2] finds anything not two, [0-9] finds any number, [.]+ finds any # of , .
  </p>
  <pre class="sourceCode Python"><code class="sourceCode python"><span class="co"># groups search for multiple conditions simultaneously; note that ^ marks the beginning of the string, and $ marks the end; unnamed groups returned as tuples, named groups as dicts:</span>
my_var = re.findall (r’’’
    ^(?P&lt;name&gt;[-\w ]+,\s[-\w ]+)\t   <span class="co"># search for lastname, firstname</span>
    (\)?\d{<span class="dv">3</span>})?\s?-?\d\{<span class="dv">3</span>}-\d{<span class="dv">4</span>})? <span class="co"># search for phone number, optional</span>
    (?&lt;email&gt;[-\w\d.+]+ @[-\w\d.]+)\t$  <span class="co"># search for emails</span>
    ‘’’, data, flags)

<span class="co"># groups addressing</span>
my_var.groups()
my_var.group_dict()
my_var.group(‘group_name’)
my_var.group(<span class="dv">1</span>)</code></pre>
  <h1 id="sources">
   <a>
    4. Sources
   </a>
  </h1>
  <h2 id="cited">
   <a>
    4.1. Cited
   </a>
  </h2>
  <p>
   Sharda, R., Delen, D., &amp; Turban, E. (2014).
   <em>
    Business intelligence: A managerial perspective on analytics
   </em>
   (3rd ed.). New York City, NY: Pearson.
  </p>
  <h2 id="references">
   <a>
    4.2. References
   </a>
  </h2>
  <ul>
   <li>
    <a href="http://billchambers.me/tutorials/2015/01/14/python-nlp-cheatsheet-nltk-scikit-learn.html">
     NLTK cheatsheet
    </a>
   </li>
   <li>
    <a href="http://corpus.byu.edu/coca/">
     Corpus of Contemporary American English
    </a>
   </li>
   <li>
    <a href="http://cw.routledge.com/textbooks/0415286239/default.asp">
     Corpus based language studies
    </a>
   </li>
   <li>
    <a href="https://personality-insights-livedemo.mybluemix.net/">
     IBM Watson demo - Infer personality from unstructured text
    </a>
   </li>
  </ul>
  <h2 id="read">
   <a>
    4.3. Read
   </a>
  </h2>
  <ul>
   <li>
    <a href="http://www.lynda.com/Regular-Expressions-tutorials/Using-Regular-Expressions/85870-2.html">
     Lynda - Using Regex
    </a>
   </li>
  </ul>
  <h2>
   <a name="4.4.-unread">
    4.4. Unread
   </a>
  </h2>
  <ul>
   <li>
    Regex:
    <a href="http://www.regular-expressions.info/">
     1
    </a>
    ,
    <a href="https://regexone.com/">
     2
    </a>
   </li>
   <li>
    <a href="https://www.codeschool.com/courses/breaking-the-ice-with-regular-expressions">
     CodeSchool - Regular Expressions
    </a>
   </li>
   <li>
    <a href="http://www.datasciencecentral.com/profiles/blogs/5-easy-steps-to-structure-highly-unstructured-big-data">
     4 steps to structure highly unstructured big data via automated indexation
    </a>
   </li>
   <li>
    <a href="https://www.coursera.org/learn/nlp">
     Coursera - Natural Language Processing
    </a>
   </li>
   <li>
    <a href="http://bigdatauniversity.com/courses/text-analytics-essentials/">
     Big Data U - Text Analytics
    </a>
   </li>
   <li>
    <a href="http://nlpers.blogspot.co.uk/2016/06/language-bias-and-black-sheep.html">
     Language bias &amp; black sheep
    </a>
   </li>
   <li>
    <a href="http://www.nltk.org/book/">
     Analyzing Text with NLTK
    </a>
   </li>
   <li>
    <a href="http://www.panix.com/~elflord/unix/grep.html">
     Donovan Rebbechi's grep tutorial
    </a>
   </li>
   <li>
    <a href="http://www.uccs.edu/~ahitchco/grep/">
     Drew's grep tutorial
    </a>
   </li>
  </ul>
 </body>
</html>
